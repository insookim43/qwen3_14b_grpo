{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Hb6Dvoi2VM"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I4w4OUE9lvo"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "furZbyFy9lvq"
      },
      "source": [
        "Read our **[Qwen3 Guide](https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune)** and check out our new **[Dynamic 2.0](https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs)** quants which outperforms other quantization methods!\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt29NJfP9lvs"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgKwzU9L9lvs"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    !pip install --no-deps unsloth vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jZhY2Dm9lvt"
      },
      "outputs": [],
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    !pip install --no-deps unsloth vllm\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    # Skip restarting message in Colab\n",
        "    import sys, re, requests; modules = list(sys.modules.keys())\n",
        "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "\n",
        "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
        "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "    !pip install -r vllm_requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkH_y8UC9lvv"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN75nmdx9lvw"
      },
      "source": [
        "Goal: To convert `Qwen3-4B-Base` into a reasoning model via GRPO by using OpenR1's Math dataset.\n",
        "\n",
        "We first pre fine-tune the model to make GRPO skip trying to match formatting - this speeds GRPO up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ce18fa7780ca487b922d00b92d1227a6",
            "5a81a44d4a794478882f63a67987435a",
            "dc829092cd484c2da2803e411d153389",
            "b8b62be38e63406d8d2cb4fa6db86edc",
            "92494cf78af649fa98dd4214d9492ea4",
            "be1f9b2ed6264b92bbf6a475f36fe92f",
            "17ec6c3377464af7ac02f3548870c588",
            "bfdca502c8d74ef9b927b4b4c5e29f5f",
            "f9ed06dfd5364358b6c9ce5d95a3e479",
            "74d9bc1eaa6b4b6b8c1a7f033a2eb2e9",
            "322e953615a24a72975b71c1c909cfa8",
            "2972c539a47f48d79943e29291c11d0c",
            "788efdf5542c4e6cb4e0d9d9febbb6dc",
            "0e9b27873868462ab0ca7cbb32445552",
            "89687394aa8b4cd597857b172cbd5652",
            "8e08c22123044b1e93a07e522fce9b3c",
            "2d142bbde03140a494b2598e26997c3b",
            "922b540434d645899d85f0e9e116071d",
            "8f4b2c217a4b403097255990e4f06e9a",
            "b3109261387d4a68ae91abe70fb5dcdd",
            "f40263911d1044cbb775c69b1784459e",
            "ce5c31da70ed4f16affb06484c50a05b"
          ]
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "c0e62914-f07d-4546-8580-507664f33bb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 05-15 11:40:11 [importing.py:53] Triton module has been replaced with a placeholder.\n",
            "INFO 05-15 11:40:11 [__init__.py:239] Automatically detected platform cuda.\n",
            "==((====))==  Unsloth 2025.5.3: Fast Qwen3 patching. Transformers: 4.51.3. vLLM: 0.8.5.post1.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/qwen3-14b-base-unsloth-bnb-4bit with actual GPU utilization = 69.2%\n",
            "Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 39.56 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 288.\n",
            "Unsloth: vLLM's KV Cache can use up to 16.72 GB. Also swap space = 6 GB.\n",
            "INFO 05-15 11:40:31 [config.py:717] This model supports multiple tasks: {'classify', 'generate', 'reward', 'score', 'embed'}. Defaulting to 'generate'.\n",
            "INFO 05-15 11:40:32 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.19.mlp', 'model.layers.38.mlp', 'model.layers.6.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 05-15 11:40:33 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='unsloth/qwen3-14b-base-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen3-14b-base-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen3-14b-base-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"backend\":\"inductor\",\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"debug\":false,\"dce\":true,\"coordinate_descent_tuning\":true,\"trace.enabled\":false,\"trace.graph_diagram\":false,\"triton.cudagraphs\":true,\"compile_threads\":48,\"max_autotune\":false,\"disable_progress\":false,\"verbose_progress\":true,\"enable_auto_functionalized_v2\":false},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
            "WARNING 05-15 11:40:33 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7c3bc2eed3d0>\n",
            "INFO 05-15 11:40:34 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
            "INFO 05-15 11:40:34 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
            "WARNING 05-15 11:40:34 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
            "INFO 05-15 11:40:34 [gpu_model_runner.py:1329] Starting to load model unsloth/qwen3-14b-base-unsloth-bnb-4bit...\n",
            "INFO 05-15 11:40:34 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n",
            "INFO 05-15 11:40:35 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
            "INFO 05-15 11:40:35 [weight_utils.py:281] Time spent downloading weights for unsloth/qwen3-14b-base-unsloth-bnb-4bit: 0.558031 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce18fa7780ca487b922d00b92d1227a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2972c539a47f48d79943e29291c11d0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 05-15 11:40:42 [punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 05-15 11:40:43 [gpu_model_runner.py:1347] Model loading took 10.4748 GiB and 8.450271 seconds\n",
            "INFO 05-15 11:41:08 [backends.py:420] Using cache directory: /root/.cache/vllm/torch_compile_cache/0a930a217e/rank_0_0 for vLLM's torch.compile\n",
            "INFO 05-15 11:41:08 [backends.py:430] Dynamo bytecode transform time: 24.92 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  4.87it/s, triton_poi_fused_add_mul_sub_5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 05-15 11:41:15 [backends.py:136] Cache the graph of shape None for later use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 10.69it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 112.91it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 111.55it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 113.38it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 110.93it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 113.58it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 115.33it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 114.39it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 106.47it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 107.36it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 118.16it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 113.26it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 114.85it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 109.16it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 104.08it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 106.62it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.33it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 108.19it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 104.51it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 107.71it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 106.64it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 107.54it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 114.93it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 107.94it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 114.41it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 101.98it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 108.17it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 110.15it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 102.57it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 113.77it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 111.88it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 112.11it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 112.03it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 108.92it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 104.43it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 106.72it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 107.97it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 106.04it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 108.72it/s, triton_poi_fused_add_mul_sub_9]\n",
            "Inductor Compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 12.28it/s, triton_red_fused__to_copy_add_mean_mul_pow_rsqrt_4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 05-15 11:42:28 [backends.py:148] Compiling a graph for general shape takes 76.55 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 05-15 11:45:09 [monitor.py:33] torch.compile takes 101.48 s in total\n",
            "INFO 05-15 11:45:12 [kv_cache_utils.py:634] GPU KV cache size: 96,608 tokens\n",
            "INFO 05-15 11:45:12 [kv_cache_utils.py:637] Maximum concurrency for 2,048 tokens per request: 47.17x\n",
            "INFO 05-15 11:47:05 [gpu_model_runner.py:1686] Graph capturing finished in 112 secs, took 1.87 GiB\n",
            "INFO 05-15 11:47:05 [core.py:159] init engine (profile, create kv cache, warmup model) took 382.32 seconds\n",
            "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'pre_feedforward_layernorm']\n",
            "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'pre_feedforward_layernorm']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.5.3 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Can increase for longer reasoning traces\n",
        "lora_rank = 8 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Qwen3-14B-Base\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.7, # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha = lora_rank*2, # *2 speeds up training\n",
        "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9DuiVRLhMco"
      },
      "source": [
        "### GRPO chat template\n",
        "Since we're using a base model, we should set a chat template. You can make your own chat template as well!\n",
        "1. DeepSeek uses `<think>` and `</think>`, but this is **not** necessary - you can customize it however you like!\n",
        "2. A `system_prompt` is recommended to at least guide the model's responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UjowCbT-cFz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "53adf9da-8451-4485-c9e7-f6f05c342329"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "reasoning_start = \"<start_working_out>\" # Acts as <think>\n",
        "reasoning_end   = \"<end_working_out>\"   # Acts as </think>\n",
        "solution_start  = \"<SOLUTION>\"\n",
        "solution_end    = \"</SOLUTION>\"\n",
        "\n",
        "system_prompt = \\\n",
        "f\"\"\"You are given a problem.\n",
        "Think about the problem and provide your working out.\n",
        "Place it between {reasoning_start} and {reasoning_end}.\n",
        "Then, provide your solution between {solution_start}{solution_end}\"\"\"\n",
        "system_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a simple chat template below. Notice `add_generation_prompt` includes prepending `<start_working_out>` to guide the model to start its reasoning process."
      ],
      "metadata": {
        "id": "zGgs0MJkDkYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = \\\n",
        "    \"{% if messages[0]['role'] == 'system' %}\"\\\n",
        "        \"{{ messages[0]['content'] + eos_token }}\"\\\n",
        "        \"{% set loop_messages = messages[1:] %}\"\\\n",
        "    \"{% else %}\"\\\n",
        "        \"{{ '{system_prompt}' + eos_token }}\"\\\n",
        "        \"{% set loop_messages = messages %}\"\\\n",
        "    \"{% endif %}\"\\\n",
        "    \"{% for message in loop_messages %}\"\\\n",
        "        \"{% if message['role'] == 'user' %}\"\\\n",
        "            \"{{ message['content'] }}\"\\\n",
        "        \"{% elif message['role'] == 'assistant' %}\"\\\n",
        "            \"{{ message['content'] + eos_token }}\"\\\n",
        "        \"{% endif %}\"\\\n",
        "    \"{% endfor %}\"\\\n",
        "    \"{% if add_generation_prompt %}{{ '{reasoning_start}' }}\"\\\n",
        "    \"{% endif %}\"\n",
        "\n",
        "# Replace with out specific template:\n",
        "chat_template = chat_template\\\n",
        "    .replace(\"'{system_prompt}'\",   f\"'{system_prompt}'\")\\\n",
        "    .replace(\"'{reasoning_start}'\", f\"'{reasoning_start}'\")\n",
        "tokenizer.chat_template = chat_template"
      ],
      "metadata": {
        "id": "Y3fF9gMujY02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how our chat template behaves on an example:"
      ],
      "metadata": {
        "id": "vEcLdymBEHdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"user\", \"content\" : \"What is 1+1?\"},\n",
        "    {\"role\" : \"assistant\", \"content\" : f\"{reasoning_start}I think it's 2.{reasoning_end}{solution_start}2{solution_end}\"},\n",
        "    {\"role\" : \"user\", \"content\" : \"What is 2+2?\"},\n",
        "], tokenize = False, add_generation_prompt = True)"
      ],
      "metadata": {
        "id": "BciEDYSSYFNj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3072ff4b-6d62-4804-e486-128e961f3e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION><|im_end|>What is 1+1?<start_working_out>I think it's 2.<end_working_out><SOLUTION>2</SOLUTION><|im_end|>What is 2+2?<start_working_out>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre fine-tuning for formatting\n",
        "We now use a subset of NVIDIA's [Open Math Reasoning dataset](https://huggingface.co/datasets/nvidia/OpenMathReasoning) which was filtered to only include high quality DeepSeek R1 traces.\n",
        "\n",
        "We'll only filter ~59 or so examples to first \"prime\" / pre fine-tune the model to understand our custom GRPO formatting."
      ],
      "metadata": {
        "id": "_mdsuGjxHrjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = load_dataset(\"unsloth/OpenMathReasoning-mini\", split = \"cot\")\n",
        "dataset = dataset.to_pandas()[\n",
        "    [\"expected_answer\", \"problem\", \"generated_solution\"]\n",
        "]\n",
        "\n",
        "# Try converting to number - if not, replace with NaN\n",
        "is_number = pd.to_numeric(pd.Series(dataset[\"expected_answer\"]), errors = \"coerce\").notnull()\n",
        "# Select only numbers\n",
        "dataset = dataset.iloc[np.where(is_number)[0]]\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "AXxM2lStVIkd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "e3667657-1c19-4642-b6ba-403370ed72e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      expected_answer                                            problem  \\\n",
              "0                  14  Given $\\sqrt{x^2+165}-\\sqrt{x^2-52}=7$ and $x$...   \n",
              "6                  -2  Find the value of the parameter $a$ for which ...   \n",
              "9                  18  What is the sum of all real numbers $x$ for wh...   \n",
              "13                  2  Evaluate the sum \\(\\sum_{n=1}^\\infty \\frac{\\ph...   \n",
              "17                 30  What is the largest positive integer that divi...   \n",
              "...               ...                                                ...   \n",
              "19243             244  Let \\( p \\), \\( q \\), and \\( r \\) be the disti...   \n",
              "19245               1  A bug is on the $0$ of a number line. At any p...   \n",
              "19247               4  A bus left point X for point Y. Two hours late...   \n",
              "19248              18  Each interior angle of a regular n-gon measure...   \n",
              "19250          0.8960  Find the probability that the second blue resu...   \n",
              "\n",
              "                                      generated_solution  \n",
              "0      <think>\\nOkay, let's see. I need to solve the ...  \n",
              "6      <think>\\nOkay, so I need to find the value of ...  \n",
              "9      <think>\\nOkay, so I need to solve the equation...  \n",
              "13     <think>\\nOkay, so I need to evaluate the infin...  \n",
              "17     <think>\\nAlright, so I need to find the larges...  \n",
              "...                                                  ...  \n",
              "19243  <think>\\nOkay, so I need to find the value of ...  \n",
              "19245  <think>\\nOkay, so I have this problem where a ...  \n",
              "19247  <think>\\nOkay, let's tackle this problem step ...  \n",
              "19248  <think>\\nOkay, let's see. I need to find the n...  \n",
              "19250  <think>\\nOkay, so I need to find the probabili...  \n",
              "\n",
              "[7507 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4060cda-5c20-4e5d-9d10-21089dce5ad1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>expected_answer</th>\n",
              "      <th>problem</th>\n",
              "      <th>generated_solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>Given $\\sqrt{x^2+165}-\\sqrt{x^2-52}=7$ and $x$...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let's see. I need to solve the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-2</td>\n",
              "      <td>Find the value of the parameter $a$ for which ...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to find the value of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>18</td>\n",
              "      <td>What is the sum of all real numbers $x$ for wh...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to solve the equation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>Evaluate the sum \\(\\sum_{n=1}^\\infty \\frac{\\ph...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to evaluate the infin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>30</td>\n",
              "      <td>What is the largest positive integer that divi...</td>\n",
              "      <td>&lt;think&gt;\\nAlright, so I need to find the larges...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19243</th>\n",
              "      <td>244</td>\n",
              "      <td>Let \\( p \\), \\( q \\), and \\( r \\) be the disti...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to find the value of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19245</th>\n",
              "      <td>1</td>\n",
              "      <td>A bug is on the $0$ of a number line. At any p...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I have this problem where a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19247</th>\n",
              "      <td>4</td>\n",
              "      <td>A bus left point X for point Y. Two hours late...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let's tackle this problem step ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19248</th>\n",
              "      <td>18</td>\n",
              "      <td>Each interior angle of a regular n-gon measure...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let's see. I need to find the n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19250</th>\n",
              "      <td>0.8960</td>\n",
              "      <td>Find the probability that the second blue resu...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to find the probabili...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7507 rows √ó 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4060cda-5c20-4e5d-9d10-21089dce5ad1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4060cda-5c20-4e5d-9d10-21089dce5ad1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4060cda-5c20-4e5d-9d10-21089dce5ad1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-887ebc11-0960-40c1-87a5-8ab59ebc54c5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-887ebc11-0960-40c1-87a5-8ab59ebc54c5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-887ebc11-0960-40c1-87a5-8ab59ebc54c5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6260efd1-940f-4781-99d9-e70f2b2290dd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6260efd1-940f-4781-99d9-e70f2b2290dd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 7507,\n  \"fields\": [\n    {\n      \"column\": \"expected_answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 868,\n        \"samples\": [\n          \"672\",\n          \"335\",\n          \"575757\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"problem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3895,\n        \"samples\": [\n          \"A club with 7 members forms three-person committees, but no two committees can have more than one member in common. What is the maximum number of committees that can be formed?\",\n          \"Find the smallest integer \\\\( a > 2 \\\\) such that \\\\( 2 \\\\mid a \\\\), \\\\( 3 \\\\mid (a+1) \\\\), \\\\( 4 \\\\mid (a+2) \\\\), \\\\( 5 \\\\mid (a+3) \\\\), and \\\\( 6 \\\\mid (a+4) \\\\).\",\n          \"Given the polynomial equation \\\\(x^3 - x = -1\\\\) with roots \\\\(a\\\\), \\\\(b\\\\), and \\\\(c\\\\), find the value of \\\\(\\\\frac{1}{1+a} + \\\\frac{1}{1+b} + \\\\frac{1}{1+c}\\\\).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated_solution\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7507,\n        \"samples\": [\n          \"<think>\\nOkay, let's see. I need to solve this problem where there are three prime numbers p, q, and r. The equations given are pq + qr + rp = 191 and p + q = r - 1. The goal is to find p + q + r. Hmm, primes, so they must be 2 or odd primes. Let me start by analyzing the problem step by step.\\n\\nFirst, the equation p + q = r - 1. If I can express r in terms of p and q, maybe I can substitute that into the first equation. Let's try that. So, from the second equation, r = p + q + 1. That seems straightforward. Now, substituting this into the first equation, we get pq + qr + rp = 191. Let's replace r with (p + q + 1).\\n\\nSo, substituting, the first equation becomes:\\n\\npq + q(p + q + 1) + p(p + q + 1) = 191.\\n\\nLet me expand each term:\\n\\nFirst term: pq.\\n\\nSecond term: q*(p + q + 1) = pq + q\\u00b2 + q.\\n\\nThird term: p*(p + q + 1) = p\\u00b2 + pq + p.\\n\\nNow, adding all these together:\\n\\npq + (pq + q\\u00b2 + q) + (p\\u00b2 + pq + p) = 191.\\n\\nCombine like terms:\\n\\npq + pq + pq = 3pq.\\n\\nq\\u00b2 + p\\u00b2.\\n\\nq + p.\\n\\nSo altogether, the equation becomes:\\n\\np\\u00b2 + q\\u00b2 + 3pq + p + q = 191.\\n\\nHmm. Let me note that.\\n\\nAlternatively, maybe I can factor this expression. Let me see. Let's try to group terms. Wait, another approach: since r = p + q + 1, then p + q + r = (p + q) + (p + q + 1) = 2(p + q) + 1. So if I can find p + q, then multiplying by 2 and adding 1 gives me the answer. That's useful. So perhaps instead of dealing with the first equation directly, I can express it in terms of p + q.\\n\\nBut maybe let's work with the equation we derived: p\\u00b2 + q\\u00b2 + 3pq + p + q = 191.\\n\\nWait, another thought: p\\u00b2 + q\\u00b2 + 3pq. Let's recall that (p + q)^2 = p\\u00b2 + 2pq + q\\u00b2, so p\\u00b2 + q\\u00b2 + 3pq = (p + q)^2 + pq.\\n\\nTherefore, the equation can be rewritten as:\\n\\n(p + q)^2 + pq + p + q = 191.\\n\\nLet me set S = p + q, and P = pq. Then the equation becomes:\\n\\nS\\u00b2 + P + S = 191.\\n\\nBut from the second equation, we know that r = S + 1, so since we need to find S + r = S + (S + 1) = 2S + 1. So our target is 2S + 1. So if we can find S, we can find the answer.\\n\\nNow, the equation is S\\u00b2 + P + S = 191. But S and P are related as S = p + q, P = pq. For two primes p and q, their sum and product. Since p and q are primes, maybe we can list possible primes that add up to S and multiply to P. However, since S and P are variables here, maybe we can express P in terms of S from the equation.\\n\\nFrom S\\u00b2 + P + S = 191, so P = 191 - S\\u00b2 - S.\\n\\nTherefore, P = -S\\u00b2 - S + 191. But P = pq must be positive, so -S\\u00b2 - S + 191 > 0. Therefore, S\\u00b2 + S < 191. Let's see the possible values of S. Since S is the sum of two primes, which are at least 2 each, so S is at least 2 + 2 = 4. Also, since S\\u00b2 + S < 191, let's solve S\\u00b2 + S - 191 < 0. Let's find the roots of S\\u00b2 + S - 191 = 0.\\n\\nUsing quadratic formula: S = [-1 \\u00b1 sqrt(1 + 4*191)] / 2 = [-1 \\u00b1 sqrt(765)] / 2. sqrt(765) is approx 27.66, so S \\u2248 (-1 + 27.66)/2 \\u2248 13.33. So the positive root is approximately 13.33, so S must be less than 13.33. Therefore, S can be integers from 4 up to 13.\\n\\nSo possible S values: 4,5,6,7,8,9,10,11,12,13.\\n\\nBut since p and q are primes, their sum S must be even or odd. Since except for 2, all primes are odd. So if both p and q are odd primes, their sum is even. If one is 2 and the other is odd, then their sum is odd. So S can be even or odd. So possible values of S (from 4 to 13) can be checked.\\n\\nBut maybe instead of all possible S, let's check possible S values from 4 to 13 and see if for each S, P = 191 - S\\u00b2 - S, and check if P can be expressed as the product of two primes that add up to S.\\n\\nAlternatively, maybe first check which S gives P as a product of two primes.\\n\\nLet's start with S=4. Then P = 191 - 16 -4 = 171. Then check if 171 can be written as product of two primes that add up to 4. But 4 is the sum. The primes could be 2 and 2 (since 2+2=4). Then 2*2=4, but P here is 171. 4 \\u2260 171, so S=4 is invalid.\\n\\nNext S=5: P=191 -25 -5=161. 161 factors into 7*23. Check if 7 + 23 = 30, which is not 5. So that's not possible. Alternatively, are there primes adding to 5? 2 and 3, since 2+3=5. Then P=2*3=6. But 6 \\u2260 161. So S=5 invalid.\\n\\nS=6: P=191 -36 -6=149. 149 is a prime number, so can't be expressed as product of two primes. So invalid.\\n\\nS=7: P=191 -49 -7=135. 135 factors into 5*27 (but 27 not prime), 3*45, 9*15, none primes. So no. So invalid.\\n\\nS=8: P=191 -64 -8=119. 119 factors into 7*17. Check if 7+17=24\\u22608. Primes adding to 8 are 3+5=8 or 5+3. Then P=15. But 15\\u2260119. So invalid.\\n\\nS=9: P=191 -81 -9=101. 101 is prime, so no.\\n\\nS=10: P=191 -100 -10=81. 81=9*9, but 9 not prime. So no.\\n\\nS=11: P=191 -121 -11=59. 59 is prime. So no.\\n\\nS=12: P=191 -144 -12=35. 35=5*7. Check if 5 +7=12? Yes! 5 +7=12. So here, S=12, which is p + q=12, and pq=35. 5 and 7 are primes. So this works.\\n\\nSo then p=5 and q=7, or p=7 and q=5. Then r = S + 1 =12 +1=13. Check if r is prime: 13 is prime. So yes. So then p, q, r are 5,7,13 or 7,5,13. Then p + q + r =5 +7 +13=25. So 25 would be the answer.\\n\\nWait, let me check S=13 as well just to be thorough. S=13: P=191 -169 -13=9. 9=3*3. Check if 3 +3=6\\u226013. So no. So no.\\n\\nTherefore, only S=12 gives valid primes. So the answer is 25.\\n\\nLet me verify the original equations. pq + qr + rp. Let p=5, q=7, r=13. Then 5*7 +7*13 +13*5 =35 +91 +65=35+91=126+65=191. Which matches. And p + q =5 +7=12. r -1=13 -1=12. So that also matches. So it's correct. Therefore, the answer is 25.\\n</think>To solve the problem where three prime numbers \\\\( p, q, \\\\) and \\\\( r \\\\) satisfy the equations \\\\( pq + qr + rp = 191 \\\\) and \\\\( p + q = r - 1 \\\\), we proceed as follows:\\n\\n1. **Express \\\\( r \\\\) in terms of \\\\( p \\\\) and \\\\( q \\\\):**\\n   From the equation \\\\( p + q = r - 1 \\\\), we can solve for \\\\( r \\\\):\\n   \\\\[\\n   r = p + q + 1\\n   \\\\]\\n\\n2. **Substitute \\\\( r \\\\) into the first equation:**\\n   Substitute \\\\( r = p + q + 1 \\\\) into the equation \\\\( pq + qr + rp = 191 \\\\):\\n   \\\\[\\n   pq + q(p + q + 1) + p(p + q + 1) = 191\\n   \\\\]\\n   Expanding and combining like terms:\\n   \\\\[\\n   pq + pq + q^2 + q + p^2 + pq + p = 191\\n   \\\\]\\n   Simplify:\\n   \\\\[\\n   p^2 + q^2 + 3pq + p + q = 191\\n   \\\\]\\n\\n3. **Introduce new variables:**\\n   Let \\\\( S = p + q \\\\) and \\\\( P = pq \\\\). The equation becomes:\\n   \\\\[\\n   S^2 + P + S = 191\\n   \\\\]\\n\\n4. **Express \\\\( r \\\\) in terms of \\\\( S \\\\):**\\n   Since \\\\( r = p + q + 1 = S + 1 \\\\), we need to find \\\\( S \\\\) such that \\\\( S^2 + P + S = 191 \\\\) and \\\\( P = pq \\\\) is the product of two primes \\\\( p \\\\) and \\\\( q \\\\) that sum to \\\\( S \\\\).\\n\\n5. **Determine possible values for \\\\( S \\\\):**\\n   Solve the inequality \\\\( S^2 + S < 191 \\\\):\\n   \\\\[\\n   S^2 + S - 191 < 0\\n   \\\\]\\n   Using the quadratic formula \\\\( S = \\\\frac{-1 \\\\pm \\\\sqrt{1 + 4 \\\\cdot 191}}{2} \\\\):\\n   \\\\[\\n   S = \\\\frac{-1 \\\\pm \\\\sqrt{765}}{2}\\n   \\\\]\\n   Since \\\\( \\\\sqrt{765} \\\\approx 27.66 \\\\), we have:\\n   \\\\[\\n   S \\\\approx \\\\frac{-1 + 27.66}{2} \\\\approx 13.33\\n   \\\\]\\n   Therefore, \\\\( S \\\\) must be an integer between 4 and 13.\\n\\n6. **Check possible values of \\\\( S \\\\):**\\n   - For \\\\( S = 12 \\\\):\\n     \\\\[\\n     P = 191 - 12^2 - 12 = 191 - 144 - 12 = 35\\n     \\\\]\\n     Check if \\\\( 35 \\\\) can be written as the product of two primes that sum to 12:\\n     \\\\[\\n     35 = 5 \\\\times 7 \\\\quad \\\\text{and} \\\\quad 5 + 7 = 12\\n     \\\\]\\n     This works. So \\\\( p = 5 \\\\) and \\\\( q = 7 \\\\).\\n\\n7. **Find \\\\( r \\\\):**\\n   \\\\[\\n   r = S + 1 = 12 + 1 = 13\\n   \\\\]\\n\\n8. **Verify the solution:**\\n   - Check \\\\( pq + qr + rp = 191 \\\\):\\n     \\\\[\\n     5 \\\\times 7 + 7 \\\\times 13 + 13 \\\\times 5 = 35 + 91 + 65 = 191\\n     \\\\]\\n   - Check \\\\( p + q = r - 1 \\\\):\\n     \\\\[\\n     5 + 7 = 12 \\\\quad \\\\text{and} \\\\quad 13 - 1 = 12\\n     \\\\]\\n\\nSince all conditions are satisfied, the final answer is:\\n\\\\[\\n\\\\boxed{25}\\n\\\\]\",\n          \"<think>\\nOkay, let's see. I need to solve this problem where x and y are positive integers satisfying 2(x + y) = gcd(x, y) + lcm(x, y). And I have to find the ratio of the lcm to the gcd of x and y. Hmm, okay, let's break this down.\\n\\nFirst, I remember that for any two positive integers, the product of the lcm and gcd of those numbers is equal to the product of the numbers themselves. So, lcm(x, y) * gcd(x, y) = x * y. That might come in handy here. Let me note that down: lcm(x,y)*gcd(x,y) = x*y.\\n\\nGiven the equation 2(x + y) = gcd(x, y) + lcm(x, y), maybe I can express everything in terms of gcd and the ratio of x and y. Since gcd and lcm are involved, it might be helpful to let d = gcd(x, y), and then express x and y as x = d*a and y = d*b, where a and b are coprime integers (their gcd is 1). That's a standard approach for problems involving gcd and lcm.\\n\\nSo let me set d = gcd(x, y). Then x = d*a, y = d*b, with gcd(a, b) = 1. Then, the lcm(x, y) would be d*a*b, because lcm(x, y) = x*y / gcd(x, y) = (d*a*d*b)/d = d*a*b. Right, so lcm(x,y) = d*a*b.\\n\\nSubstituting these into the original equation: 2(x + y) = gcd(x, y) + lcm(x, y).\\n\\nSubstituting x = d*a, y = d*b, gcd = d, lcm = d*a*b. Then:\\n\\n2(d*a + d*b) = d + d*a*b.\\n\\nFactor out d from the left side: 2d(a + b) = d(1 + a*b).\\n\\nSince d is a positive integer, we can divide both sides by d, yielding:\\n\\n2(a + b) = 1 + a*b.\\n\\nSo now the equation simplifies to 2(a + b) = a*b + 1, where a and b are coprime positive integers. Hmm, okay. Now we have a simpler equation to solve: a*b - 2a - 2b + 1 = 0. Let me rearrange that:\\n\\na*b - 2a - 2b + 1 = 0.\\n\\nHmm, maybe factor this equation? Let me see. Adding 4 to both sides might help in factoring. Let's try:\\n\\na*b - 2a - 2b + 1 + 4 - 4 = 0\\n\\nSo, a*b - 2a - 2b + 4 = 3.\\n\\nWait, not sure. Alternatively, perhaps rearrange the terms:\\n\\na*b - 2a - 2b = -1.\\n\\nThen, add 4 to both sides:\\n\\na*b - 2a - 2b + 4 = 3.\\n\\nNow, left side can be factored as (a - 2)(b - 2) = 3. Because expanding (a - 2)(b - 2) gives a*b - 2a - 2b + 4. Yes, that's right. So:\\n\\n(a - 2)(b - 2) = 3.\\n\\nSince a and b are positive integers and coprime, we need to find pairs (a, b) such that their product is 3 when each is reduced by 2. Also, since a and b are coprime, (a - 2) and (b - 2) must be divisors of 3, which is prime. The positive divisors of 3 are 1 and 3.\\n\\nSo possible pairs (since a and b are positive integers, a - 2 and b - 2 must be at least such that a and b are positive. Let's see:\\n\\nCase 1: (a - 2) = 1 and (b - 2) = 3. Then, a = 3, b = 5. Check if gcd(a, b) = 1. gcd(3, 5) = 1, which is good.\\n\\nCase 2: (a - 2) = 3 and (b - 2) = 1. Then, a = 5, b = 3. Similarly, gcd(5, 3) = 1. So this is also valid.\\n\\nBut also, since 3 is prime, the only positive divisors are 1 and 3. But since we're considering positive integers, we could also consider if one of them is negative? But since a and b are positive, a - 2 and b - 2 must be positive or zero? Wait, but 3 is positive, so the factors must both be positive. Because if one of (a - 2) or (b - 2) were negative, their product would be negative, but 3 is positive. So both (a - 2) and (b - 2) must be positive. Thus, only the two cases above.\\n\\nAlternatively, maybe (a - 2) and (b - 2) could be 3 and 1 in some order, which gives the two cases. So the possible (a, b) are (3, 5) and (5, 3). Since a and b are interchangeable (since x and y are symmetric in the problem), these two cases would yield the same results.\\n\\nSo now, let's see. For (a, b) = (3, 5), then x = d*3, y = d*5. Similarly, for (a, b) = (5, 3), x = d*5, y = d*3. But since the problem is symmetric in x and y, both cases are equivalent.\\n\\nNow, since we need to find the ratio lcm(x, y)/gcd(x, y), let's compute that.\\n\\nRecall that lcm(x, y)/gcd(x, y) = (d*a*b)/d = a*b. So it's simply a*b. Since in both cases, a and b are 3 and 5, the product is 15. Therefore, the ratio is 15.\\n\\nWait, that seems too straightforward. Let me check.\\n\\nIf the ratio is a*b, then yes. Because lcm(x, y) is d*a*b and gcd(x, y) is d, so their ratio is (d*a*b)/d = a*b. Since a and b are 3 and 5, 3*5=15. Therefore, the answer is 15. So the answer is 15.\\n\\nBut let me verify with an example. Let's take d=1. Then x=3, y=5. Then gcd(3,5)=1, lcm=15. Then 2(x + y) = 2*(8) = 16. The right side is 1 + 15=16. So that works. If d=1, then 2(3+5)=16=1 +15.\\n\\nWhat if d=2? Then x=6, y=10. gcd(6,10)=2, lcm=30. Then 2(6 + 10)=2*16=32. The right side is 2 +30=32. So that also works. Then the ratio lcm/gcd is 30/2=15. So regardless of d, the ratio is always 15. Wait, because if x = d*a, y = d*b, then lcm(x,y)/gcd(x,y) = (d*a*b)/d = a*b, which is 15 as in the first case. So regardless of d, the ratio is always 15. Therefore, the answer is 15.\\n\\nSo even if d is some other positive integer, the ratio remains a*b =15. Therefore, the required ratio is 15.\\n\\nTherefore, the answer is 15. So \\\\boxed{15}.\\n\\n**Final Answer**\\n\\\\boxed{15}\\n</think>Given \\\\( x \\\\) and \\\\( y \\\\) are positive integers such that \\\\( 2(x + y) = \\\\gcd(x, y) + \\\\text{lcm}(x, y) \\\\), we need to find \\\\( \\\\frac{\\\\text{lcm}(x, y)}{\\\\gcd(x, y)} \\\\).\\n\\nFirst, let \\\\( d = \\\\gcd(x, y) \\\\). Then, we can express \\\\( x \\\\) and \\\\( y \\\\) as \\\\( x = d \\\\cdot a \\\\) and \\\\( y = d \\\\cdot b \\\\), where \\\\( \\\\gcd(a, b) = 1 \\\\). The least common multiple (lcm) of \\\\( x \\\\) and \\\\( y \\\\) is given by \\\\( \\\\text{lcm}(x, y) = d \\\\cdot a \\\\cdot b \\\\).\\n\\nSubstituting these into the given equation:\\n\\\\[\\n2(d \\\\cdot a + d \\\\cdot b) = d + d \\\\cdot a \\\\cdot b\\n\\\\]\\nDividing both sides by \\\\( d \\\\):\\n\\\\[\\n2(a + b) = 1 + a \\\\cdot b\\n\\\\]\\nRearranging terms, we get:\\n\\\\[\\na \\\\cdot b - 2a - 2b + 1 = 0\\n\\\\]\\nAdding 4 to both sides to factorize:\\n\\\\[\\na \\\\cdot b - 2a - 2b + 4 = 3\\n\\\\]\\nThis can be factored as:\\n\\\\[\\n(a - 2)(b - 2) = 3\\n\\\\]\\nThe positive integer solutions for \\\\((a - 2)\\\\) and \\\\((b - 2)\\\\) are 1 and 3. Thus, the possible pairs \\\\((a, b)\\\\) are \\\\((3, 5)\\\\) and \\\\((5, 3)\\\\). Since \\\\( a \\\\) and \\\\( b \\\\) are coprime, both pairs are valid.\\n\\nThe ratio \\\\( \\\\frac{\\\\text{lcm}(x, y)}{\\\\gcd(x, y)} \\\\) is given by:\\n\\\\[\\n\\\\frac{\\\\text{lcm}(x, y)}{\\\\gcd(x, y)} = \\\\frac{d \\\\cdot a \\\\cdot b}{d} = a \\\\cdot b\\n\\\\]\\nFor both pairs \\\\((3, 5)\\\\) and \\\\((5, 3)\\\\), the product \\\\( a \\\\cdot b = 15 \\\\).\\n\\nThus, the final answer is:\\n\\\\[\\n\\\\boxed{15}\\n\\\\]\",\n          \"<think>\\nOkay, so I need to find the remainder when the product of all odd numbers from 1 to 2005 is divided by 1000. Hmm, let's think about how to approach this. \\n\\nFirst, the product is 1 \\u00d7 3 \\u00d7 5 \\u00d7 ... \\u00d7 2005. That's a lot of numbers! Since we're dealing with division by 1000, maybe modular arithmetic can help here. The remainder when divided by 1000 is equivalent to the product modulo 1000. But calculating such a huge product directly seems impossible. There has to be a smarter way.\\n\\nI remember that when dealing with factorials and remainders, factors of 2 and 5 can create trailing zeros. However, here we're only multiplying odd numbers, so there are no factors of 2. But there might still be factors of 5. Wait, 1000 is 8\\u00d7125, which is 2^3 \\u00d7 5^3. Since the product is all odd numbers, it won't have factors of 2, but it can have factors of 5. Therefore, the product will be divisible by 5^3, but since there are no 2s, the product modulo 1000 might not be zero. Hmm, maybe I need to compute the product modulo 1000, but adjusting for the factors of 5?\\n\\nAlternatively, maybe split the problem into modulo 8 and modulo 125, then use the Chinese Remainder Theorem (CRT) to combine the results. Since 1000 = 8 \\u00d7 125, and 8 and 125 are coprime, CRT says that if I can find the remainder modulo 8 and modulo 125, then I can combine them to find the remainder modulo 1000. That might be a good approach.\\n\\nLet me start with modulo 8. The product is 1\\u00d73\\u00d75\\u00d77\\u00d79\\u00d7...\\u00d72005. But modulo 8, odd numbers repeat every 8 numbers. Let's see, the residues modulo 8 of odd numbers are 1,3,5,7,1,3,5,7,... So the pattern repeats every 4 terms. Wait, no. Wait, the numbers go 1,3,5,7,9\\u22611,11\\u22613,13\\u22615,15\\u22617, etc. So every 8 numbers, the cycle of residues 1,3,5,7 repeats twice. Wait, actually, modulo 8, the odd residues cycle every 4 numbers. Let's confirm:\\n\\n1 mod 8 =1\\n\\n3 mod8=3\\n\\n5 mod8=5\\n\\n7 mod8=7\\n\\n9 mod8=1\\n\\n11 mod8=3\\n\\n13 mod8=5\\n\\n15 mod8=7\\n\\nYes, every 4 terms, the cycle repeats. So how many terms are in the product 1\\u00d73\\u00d75\\u00d7...\\u00d72005? Let's find the number of terms first. The nth odd number is 2n-1. So 2n-1=2005 => n=(2005+1)/2=2006/2=1003. So there are 1003 terms.\\n\\nSo 1003 terms, each group of 4 terms (mod8) is 1\\u00d73\\u00d75\\u00d77=105. Then 105 mod8= 105 - 13\\u00d78=105-104=1. So each group of 4 terms multiplies to 1 mod8. Then how many full groups of 4 are there in 1003 terms? Let's divide 1003 by 4. 1003 \\u00f74=250.75. So 250 full groups, each contributing 1 mod8, and then a remainder of 3 terms. \\n\\nSo the total product modulo8 is (1^250) \\u00d7 (last three terms). The last three terms would be the terms after the 250th group. The 250th group ends at term 250\\u00d74=1000. So the 1001st term is 2\\u00d71001 -1=2001. Wait, no: the first term is 1=2\\u00d71-1, second term 3=2\\u00d72-1, so term k is 2k-1. Therefore, term 1001 is 2\\u00d71001 -1=2002-1=2001. Then the 1002nd term is 2003, 1003rd term is 2005. So the last three terms are 2001, 2003, 2005. Let's compute each mod8:\\n\\n2001 \\u00f78: 8\\u00d7250=2000, so 2001 mod8=1\\n\\n2003 mod8=3\\n\\n2005 mod8=5\\n\\nSo the last three terms modulo8 are 1\\u00d73\\u00d75=15 mod8=7.\\n\\nTherefore, total product mod8 is (1^250) \\u00d77=1\\u00d77=7 mod8.\\n\\nSo the remainder modulo8 is7.\\n\\nNow, we need to compute the product modulo125. This seems more complicated. Let's think.\\n\\nThe product is the product of all odd numbers from1 to2005. Wait, 2005=5\\u00d7401. So we can write the product as (1\\u00d73\\u00d75\\u00d77\\u00d7...\\u00d72005). Let's note that there are a lot of factors of 5 in this product, which would make the product divisible by 5 multiple times. However, modulo125 is 5^3, so if the product has at least three factors of 5, then modulo125 would be 0. Wait, but maybe even if it's divisible by 5^3, but we need to compute the actual remainder. Wait, but perhaps the product is divisible by 5^3, but when divided by 5^3, the remaining product modulo8 or something else. Wait, maybe not. Let me check how many factors of5 are in the product.\\n\\nThe number of factors of5 in the product:\\n\\nEach multiple of5 contributes at least one factor of5. Since we're dealing with odd numbers, the multiples of5 that are odd. So numbers divisible by5 but not by2. So numbers like5,15,25,...,2005. Let's count how many multiples of5 are in the product. The first term is5, which is5\\u00d71, then15=5\\u00d73,..., up to2005=5\\u00d7401. So the multiples of5 are5\\u00d7(1,3,5,...,401). Wait, 5\\u00d7k, where k is odd from1 to401. Because 5\\u00d7401=2005. So how many terms are there?\\n\\nThe number of terms k from1 to401 where k is odd. Since401 is odd, the number is (401 +1)/2=201. So there are201 multiples of5 in the product. Each contributes at least one factor of5. Additionally, multiples of25 contribute an extra factor of5. Similarly, multiples of125, 625, etc., contribute more factors.\\n\\nSo let's compute the total number of factors of5 in the product.\\n\\nNumber of multiples of5:201 (as above)\\n\\nNumber of multiples of25: These are numbers in the product divisible by25. Since the product includes numbers of the form5\\u00d7(odd numbers). So multiples of25 are numbers divisible by25, which are 25,75,125,...,2000. But 2005 is not divisible by25. Wait, wait, in the original product (all odd numbers up to2005), the multiples of25 must be odd multiples. So 25\\u00d71,25\\u00d73,..., up to the largest odd multiple less than or equal to2005.\\n\\n25\\u00d7k \\u22642005, where k is odd. Let's compute k_max:\\n\\n25k \\u22642005 => k \\u22642005/25=80.2. So the largest integer k is80, but since k has to be odd, the largest odd k is79. So 25\\u00d779=1975. Then 25\\u00d781=2025, which is over. So the multiples of25 in the product are25\\u00d71,25\\u00d73,...,25\\u00d779. Number of terms: (79-1)/2 +1=39 +1=40. Wait, from1 to79 odd numbers: number is (79+1)/2=40. So there are40 multiples of25.\\n\\nSimilarly, multiples of125:125\\u00d71,125\\u00d73,..., up to125\\u00d7k\\u22642005. 125\\u00d7k \\u22642005 =>k\\u226416.04. So k_max=15 (odd). So 125\\u00d715=1875. So multiples are125\\u00d71,125\\u00d73,...,125\\u00d715. Number of terms: (15-1)/2 +1=7+1=8.\\n\\nMultiples of625:625\\u00d71=625, next is625\\u00d73=1875, next is625\\u00d75=3125>2005. So only two multiples:625 and1875. But1875 is already counted as a multiple of125. So factors of625 contribute an extra factor of5 each. So number of multiples of625 is 2. 625 and1875.\\n\\nMultiples of3125:3125>2005, so none.\\n\\nSo total number of factors of5:\\n\\nFrom multiples of5:201\\n\\nFrom multiples of25:40 (each contributes an extra)\\n\\nFrom multiples of125:8 (each contributes another extra)\\n\\nFrom multiples of625:2 (each contributes another extra)\\n\\nTotal:201 +40 +8 +2=251.\\n\\nSo total factors of5 in the product:251.\\n\\nSimilarly, factors of2: since all numbers are odd, there are none. So the product is divisible by5^251 but not by2. So when dividing by5^3, since 251\\u22653, the product is divisible by5^3. Therefore, the product modulo125 is0? Wait, no, wait. Wait, 125 is5^3. If the product has at least three factors of5, then when divided by5^3, the quotient is an integer, but the remainder when divided by125 is0. So if the product is divisible by125, then the remainder is0. But the question is, when we divide the product by1000, which is8\\u00d7125, the remainder is to be found. However, we already considered that modulo8 is7, and modulo125 is... Hmm, but if modulo125 is0, then using CRT, we can say the remainder is a number congruent to7 mod8 and0 mod125. So we need to solve for x\\u22610 mod125 andx\\u22617 mod8.\\n\\nBut wait, let me confirm if modulo125 is indeed0. Let's check: since the product has at least three factors of5, then yes, the product is divisible by5^3, so product \\u22610 mod125. Therefore, modulo125 is0. Therefore, we have:\\n\\nx \\u22617 mod8\\n\\nx \\u22610 mod125\\n\\nWe need to find x such that x \\u22610 mod125 andx \\u22617 mod8. Let\\u2019s solve this system.\\n\\nLet x=125k. Then 125k\\u22617 mod8. Since125 mod8=5, so 5k\\u22617 mod8.\\n\\nWe solve 5k\\u22617 mod8.\\n\\nMultiply both sides by inverse of5 mod8. The inverse of5 mod8 is5, since5\\u00d75=25\\u22611 mod8. So multiply both sides by5:\\n\\nk\\u22617\\u00d75 mod8 =>k\\u226135 mod8 =>35\\u00f78=4*8=32, 35-32=3. So k\\u22613 mod8.\\n\\nTherefore, k=8m +3 for some integer m. Therefore, x=125(8m +3)=1000m +375. Therefore, the smallest non-negative solution is375. Therefore, the remainder is375 when divided by1000. So the answer is375.\\n\\nWait, but before accepting that, let me verify my steps again because this is tricky.\\n\\nFirst, confirming that the product is divisible by5^3: yes, since there are 251 factors of5, so 5^251 divides the product. Therefore, the product is divisible by5^3, so product\\u22610 mod125. That's correct.\\n\\nThen, solving x\\u22617 mod8 and x\\u22610 mod125. So x=125k. Then 125k\\u22615k mod8. So 5k\\u22617 mod8. Multiply both sides by inverse of5 mod8, which is5, since5\\u00d75=25\\u22611 mod8. So k\\u226135 mod8\\u22613 mod8. Therefore, k=8m +3, so x=125\\u00d73 +1000m=375 +1000m. So the minimal positive solution is375. So remainder is375 when divided by1000. That seems correct.\\n\\nBut wait, to make sure, let me check with an example. Let's take x=375. 375 \\u00f78=46*8=368, remainder7. So 375 mod8=7. 375 mod125=0. So yes, 375 satisfies both conditions. Therefore, the remainder is375. Therefore, the answer is\\\\boxed{375}.\\n\\nWait, but I need to make sure that my calculation for modulo8 and modulo125 are correct. Let me double-check the modulo8 calculation.\\n\\nEarlier, I considered that the product modulo8 is7. Let me recast that.\\n\\nThe product is1\\u00d73\\u00d75\\u00d77\\u00d7\\u2026\\u00d72005. When taking modulo8, each cycle of4 terms (1,3,5,7) multiplies to1\\u00d73\\u00d75\\u00d77=105\\u22611 mod8. Since 105/8=13\\u00d78=104, 105-104=1. Then, since there are1003 terms, how many cycles of4 are there? 1003 divided by4 is250 cycles with a remainder of3 terms. Then the product is (1)^250 \\u00d7 last3 terms.\\n\\nThe last3 terms are2001,2003,2005. 2001 mod8=1 (2001-8\\u00d7250=2001-2000=1), 2003=2001+2\\u21921+2=3 mod8, 2005=2001+4\\u21921+4=5 mod8. So last3 terms are1\\u00d73\\u00d75=15\\u22617 mod8. Therefore, total product\\u22611^250 \\u00d77\\u22617 mod8. Correct.\\n\\nTherefore, the logic holds. Therefore, the remainder is375. So I think that's the correct answer.\\n\\n**Final Answer**\\n\\\\boxed{375}\\n</think>To find the remainder when the product \\\\(1 \\\\times 3 \\\\times 5 \\\\times \\\\cdots \\\\times 2005\\\\) is divided by 1000, we use modular arithmetic and the Chinese Remainder Theorem (CRT).\\n\\n### Step 1: Calculate the product modulo 8\\n\\nThe sequence of odd numbers modulo 8 repeats every 4 terms: \\\\(1, 3, 5, 7\\\\). The product of each cycle is:\\n\\\\[\\n1 \\\\times 3 \\\\times 5 \\\\times 7 = 105 \\\\equiv 1 \\\\mod 8\\n\\\\]\\n\\nThere are 1003 terms in the product. Dividing 1003 by 4 gives 250 full cycles and a remainder of 3 terms. The remaining terms are 2001, 2003, and 2005. We calculate these modulo 8:\\n\\\\[\\n2001 \\\\equiv 1 \\\\mod 8, \\\\quad 2003 \\\\equiv 3 \\\\mod 8, \\\\quad 2005 \\\\equiv 5 \\\\mod 8\\n\\\\]\\nThe product of these remaining terms is:\\n\\\\[\\n1 \\\\times 3 \\\\times 5 = 15 \\\\equiv 7 \\\\mod 8\\n\\\\]\\n\\nThus, the product modulo 8 is:\\n\\\\[\\n1^{250} \\\\times 7 \\\\equiv 7 \\\\mod 8\\n\\\\]\\n\\n### Step 2: Calculate the product modulo 125\\n\\nWe need to determine the number of factors of 5 in the product. The sequence of odd numbers includes multiples of 5, 25, 125, and 625.\\n\\n- Multiples of 5: \\\\(5, 15, 25, \\\\ldots, 2005\\\\)\\n  - These are of the form \\\\(5 \\\\times (2k+1)\\\\) for \\\\(k = 0, 1, 2, \\\\ldots, 200\\\\)\\n  - Number of such terms: \\\\(\\\\frac{2005}{5} = 401\\\\), and half of these are odd, so \\\\(201\\\\) multiples of 5.\\n\\n- Multiples of 25: \\\\(25, 75, 125, \\\\ldots, 1975\\\\)\\n  - These are of the form \\\\(25 \\\\times (2k+1)\\\\) for \\\\(k = 0, 1, 2, \\\\ldots, 39\\\\)\\n  - Number of such terms: \\\\(\\\\frac{1975}{25} = 79\\\\), and half of these are odd, so \\\\(40\\\\) multiples of 25.\\n\\n- Multiples of 125: \\\\(125, 375, 625, 875, 1125, 1375, 1625, 1875\\\\)\\n  - These are of the form \\\\(125 \\\\times (2k+1)\\\\) for \\\\(k = 0, 1, 2, \\\\ldots, 15\\\\)\\n  - Number of such terms: \\\\(\\\\frac{1875}{125} = 15\\\\), and half of these are odd, so \\\\(8\\\\) multiples of 125.\\n\\n- Multiples of 625: \\\\(625, 1875\\\\)\\n  - These are of the form \\\\(625 \\\\times (2k+1)\\\\) for \\\\(k = 0, 1\\\\)\\n  - Number of such terms: \\\\(\\\\frac{1875}{625} = 3\\\\), and half of these are odd, so \\\\(2\\\\) multiples of 625.\\n\\nTotal factors of 5:\\n\\\\[\\n201 + 40 + 8 + 2 = 251\\n\\\\]\\n\\nSince \\\\(251 \\\\geq 3\\\\), the product is divisible by \\\\(5^3 = 125\\\\). Therefore, the product modulo 125 is:\\n\\\\[\\n0 \\\\mod 125\\n\\\\]\\n\\n### Step 3: Combine results using the Chinese Remainder Theorem\\n\\nWe have:\\n\\\\[\\nx \\\\equiv 7 \\\\mod 8\\n\\\\]\\n\\\\[\\nx \\\\equiv 0 \\\\mod 125\\n\\\\]\\n\\nLet \\\\(x = 125k\\\\). Then:\\n\\\\[\\n125k \\\\equiv 7 \\\\mod 8\\n\\\\]\\nSince \\\\(125 \\\\equiv 5 \\\\mod 8\\\\), we have:\\n\\\\[\\n5k \\\\equiv 7 \\\\mod 8\\n\\\\]\\n\\nThe multiplicative inverse of 5 modulo 8 is 5, so:\\n\\\\[\\nk \\\\equiv 7 \\\\times 5 \\\\equiv 35 \\\\equiv 3 \\\\mod 8\\n\\\\]\\n\\nThus, \\\\(k = 8m + 3\\\\) for some integer \\\\(m\\\\). Therefore:\\n\\\\[\\nx = 125(8m + 3) = 1000m + 375\\n\\\\]\\n\\nThe smallest non-negative solution is:\\n\\\\[\\nx = 375\\n\\\\]\\n\\nTherefore, the remainder when the product is divided by 1000 is:\\n\\\\[\\n\\\\boxed{375}\\n\\\\]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to format the dataset to follow our GRPO style formatting:"
      ],
      "metadata": {
        "id": "JVRFqoSdIEVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(x):\n",
        "    expected_answer = x[\"expected_answer\"]\n",
        "    problem = x[\"problem\"]\n",
        "\n",
        "    # Remove generated <think> and </think>\n",
        "    thoughts = x[\"generated_solution\"]\n",
        "    thoughts = thoughts.replace(\"<think>\", \"\").replace(\"</think>\", \"\")\n",
        "\n",
        "    # Strip newlines on left and right\n",
        "    thoughts = thoughts.strip()\n",
        "    # Add our custom formatting\n",
        "    final_prompt = \\\n",
        "        reasoning_start + thoughts + reasoning_end + \\\n",
        "        solution_start + expected_answer + solution_end\n",
        "    return [\n",
        "        {\"role\" : \"system\",    \"content\" : system_prompt},\n",
        "        {\"role\" : \"user\",      \"content\" : problem},\n",
        "        {\"role\" : \"assistant\", \"content\" : final_prompt},\n",
        "    ]\n",
        "\n",
        "dataset[\"Messages\"] = dataset.apply(format_dataset, axis = 1)"
      ],
      "metadata": {
        "id": "Z9ydcV_Abfi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check to see if it worked:"
      ],
      "metadata": {
        "id": "X5NI47rOIRP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.apply_chat_template(dataset[\"Messages\"][0], tokenize = False)"
      ],
      "metadata": {
        "id": "LTdXBKcslhRH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "7b4f4be4-6b6a-41ec-cdd1-7f925c370cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION><|im_end|>Given $\\\\sqrt{x^2+165}-\\\\sqrt{x^2-52}=7$ and $x$ is positive, find all possible values of $x$.<start_working_out>Okay, let's see. I need to solve the equation ‚àö(x¬≤ + 165) - ‚àö(x¬≤ - 52) = 7, and find all positive values of x. Hmm, radicals can be tricky, but maybe if I can eliminate the square roots by squaring both sides. Let me try that.\\n\\nFirst, let me write down the equation again to make sure I have it right:\\n\\n‚àö(x¬≤ + 165) - ‚àö(x¬≤ - 52) = 7.\\n\\nOkay, so the idea is to isolate one of the radicals and then square both sides. Let me try moving the second radical to the other side:\\n\\n‚àö(x¬≤ + 165) = 7 + ‚àö(x¬≤ - 52).\\n\\nNow, if I square both sides, maybe I can get rid of the square roots. Let's do that:\\n\\n(‚àö(x¬≤ + 165))¬≤ = (7 + ‚àö(x¬≤ - 52))¬≤.\\n\\nSimplifying the left side:\\n\\nx¬≤ + 165 = 49 + 14‚àö(x¬≤ - 52) + (‚àö(x¬≤ - 52))¬≤.\\n\\nThe right side is expanded using the formula (a + b)¬≤ = a¬≤ + 2ab + b¬≤. So the right side becomes 7¬≤ + 2*7*‚àö(x¬≤ - 52) + (‚àö(x¬≤ - 52))¬≤, which is 49 + 14‚àö(x¬≤ - 52) + (x¬≤ - 52).\\n\\nSo putting it all together:\\n\\nx¬≤ + 165 = 49 + 14‚àö(x¬≤ - 52) + x¬≤ - 52.\\n\\nHmm, let's simplify the right side. The x¬≤ terms will cancel out, right? Let's subtract x¬≤ from both sides:\\n\\n165 = 49 + 14‚àö(x¬≤ - 52) - 52.\\n\\nSimplify the constants on the right:\\n\\n49 - 52 is -3, so:\\n\\n165 = -3 + 14‚àö(x¬≤ - 52).\\n\\nNow, add 3 to both sides to isolate the radical term:\\n\\n165 + 3 = 14‚àö(x¬≤ - 52).\\n\\nSo 168 = 14‚àö(x¬≤ - 52).\\n\\nDivide both sides by 14:\\n\\n168 / 14 = ‚àö(x¬≤ - 52).\\n\\n12 = ‚àö(x¬≤ - 52).\\n\\nNow, square both sides again to eliminate the square root:\\n\\n12¬≤ = x¬≤ - 52.\\n\\n144 = x¬≤ - 52.\\n\\nAdd 52 to both sides:\\n\\n144 + 52 = x¬≤.\\n\\n196 = x¬≤.\\n\\nSo x = ‚àö196 = 14.\\n\\nBut wait, since the problem states that x is positive, we only take the positive root. So x = 14.\\n\\nBut hold on, when dealing with squaring equations, sometimes extraneous solutions can come up. I should check if this solution actually satisfies the original equation.\\n\\nLet's plug x = 14 back into the original equation:\\n\\n‚àö(14¬≤ + 165) - ‚àö(14¬≤ - 52) = ?\\n\\nCalculate each term:\\n\\n14¬≤ is 196.\\n\\nSo first radical: ‚àö(196 + 165) = ‚àö361 = 19.\\n\\nSecond radical: ‚àö(196 - 52) = ‚àö144 = 12.\\n\\nSo 19 - 12 = 7, which is exactly the right-hand side. So yes, it checks out.\\n\\nTherefore, the only solution is x = 14. Since the problem says x is positive, we don't have to consider negative roots. So I think that's the answer.\\nTo solve the equation \\\\(\\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\\\) for positive \\\\(x\\\\), we proceed as follows:\\n\\n1. Start with the given equation:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\n   \\\\]\\n\\n2. Isolate one of the square roots by moving \\\\(\\\\sqrt{x^2 - 52}\\\\) to the right side:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} = 7 + \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n3. Square both sides to eliminate the square root on the left:\\n   \\\\[\\n   (\\\\sqrt{x^2 + 165})^2 = (7 + \\\\sqrt{x^2 - 52})^2\\n   \\\\]\\n   Simplifying both sides, we get:\\n   \\\\[\\n   x^2 + 165 = 49 + 14\\\\sqrt{x^2 - 52} + (x^2 - 52)\\n   \\\\]\\n\\n4. Combine like terms on the right side:\\n   \\\\[\\n   x^2 + 165 = x^2 - 52 + 49 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n   Simplifying further:\\n   \\\\[\\n   x^2 + 165 = x^2 - 3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n5. Subtract \\\\(x^2\\\\) from both sides:\\n   \\\\[\\n   165 = -3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n6. Add 3 to both sides to isolate the term with the square root:\\n   \\\\[\\n   168 = 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n7. Divide both sides by 14:\\n   \\\\[\\n   12 = \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n8. Square both sides again to eliminate the square root:\\n   \\\\[\\n   12^2 = x^2 - 52\\n   \\\\]\\n   Simplifying:\\n   \\\\[\\n   144 = x^2 - 52\\n   \\\\]\\n\\n9. Add 52 to both sides to solve for \\\\(x^2\\\\):\\n   \\\\[\\n   196 = x^2\\n   \\\\]\\n\\n10. Take the positive square root (since \\\\(x\\\\) is positive):\\n    \\\\[\\n    x = \\\\sqrt{196} = 14\\n    \\\\]\\n\\n11. Verify the solution by substituting \\\\(x = 14\\\\) back into the original equation:\\n    \\\\[\\n    \\\\sqrt{14^2 + 165} - \\\\sqrt{14^2 - 52} = \\\\sqrt{196 + 165} - \\\\sqrt{196 - 52} = \\\\sqrt{361} - \\\\sqrt{144} = 19 - 12 = 7\\n    \\\\]\\n    The solution checks out.\\n\\nThus, the only positive solution is:\\n\\\\[\\n\\\\boxed{14}\\n\\\\]<end_working_out><SOLUTION>14</SOLUTION><|im_end|>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's truncate the pre fine-tuning dataset to `max_seq_length/2` since we don't want too long reasoning traces.\n",
        "\n",
        "Note this might take 2 minutes!"
      ],
      "metadata": {
        "id": "iHV9BXYiIYaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"N\"] = dataset[\"Messages\"].apply(lambda x: len(tokenizer.apply_chat_template(x)))\n",
        "\n",
        "dataset = dataset.loc[dataset[\"N\"] <= max_seq_length-256].copy()\n",
        "dataset.shape\n"
      ],
      "metadata": {
        "id": "MBHFlRbae9_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b4104d-8152-4792-cbb4-32dc963b51a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(731, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q73htDNuiVzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then tokenize the messages and convert it to a Hugging Face compatible dataset format:"
      ],
      "metadata": {
        "id": "E6NkUCAGIj8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset[\"text\"] = tokenizer.apply_chat_template(dataset[\"Messages\"].values.tolist(), tokenize = False)\n",
        "dataset = Dataset.from_pandas(dataset)\n",
        "dataset"
      ],
      "metadata": {
        "id": "3rgdtiV_f5hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185b1b6b-7fb2-4c48-d4ff-b168a622ed09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['expected_answer', 'problem', 'generated_solution', 'Messages', 'N', 'text', '__index_level_0__'],\n",
              "    num_rows: 731\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now pre fine-tune the model so it follows our custom GRPO formatting!"
      ],
      "metadata": {
        "id": "bAQJjQrYKzOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    args = SFTConfig(\n",
        "        dataset_text_field = \"text\",\n",
        "        per_device_train_batch_size = 1,\n",
        "        gradient_accumulation_steps = 1, # Use GA to mimic batch size!\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 2, # Set this for 1 full training run.\n",
        "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
        "        logging_steps = 5,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "woYi0SSygpqp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "dc9d7f74029f40349bad2140679099fc",
            "94ebf11421ce4070a476538a1e84cf4e",
            "b848e45976c342c08efe73d51b64dac1",
            "fcc310e2f2af4edd8bd173b36d8e50a4",
            "4bec0bc98cd24745a99ccbce901ddbd1",
            "84c7fd6694974428a151c6f6184445f9",
            "0de1cfc3e65148fd91c7384ede502679",
            "707058e0ef904f8195986941ec096f53",
            "c2368d4d150f4dae90a0c849ce026a7d",
            "2b4a7c022406472588f6502e5b69c076",
            "7fc31e9fde424247abe0da03cb767c27"
          ]
        },
        "outputId": "b3a6b0d2-44fb-4331-bc51-8fc801766f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=12):   0%|          | 0/731 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc9d7f74029f40349bad2140679099fc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "l4-2v_bLhZuE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bbad2cb7-2508-4136-a462-66aa9f97ccdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 731 | Num Epochs = 2 | Total steps = 1,462\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 1 x 1) = 1\n",
            " \"-____-\"     Trainable parameters = 32,112,640/14,000,000,000 (0.23% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1462' max='1462' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1462/1462 24:59, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.721400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.729700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.516700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.419100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.470900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.356800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.392900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.393900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.395000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.398500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.402000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.322900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.523300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.380100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.350900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.370200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.520600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.418800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.406100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.378800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.395100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.393900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.367000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.418300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.334400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.416500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.457500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.384500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.333600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.407700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.379800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.354600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.386200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.417900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.372200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.391400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.339100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.326900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.341100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.296400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.396200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.431600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.442100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.516000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.376700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.385900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>0.353500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.447700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.367600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.362700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.355100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>0.284600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.295600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.320900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.363300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.296100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.396100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>0.349400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.320200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>0.402700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.404100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>0.314600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.436700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.340200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.324900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>0.424500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.334200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.346700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.397500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>0.322700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.366700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>0.396600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.427500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.380800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.272700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>385</td>\n",
              "      <td>0.373500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.382100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>395</td>\n",
              "      <td>0.348800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.319500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>405</td>\n",
              "      <td>0.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.320600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>415</td>\n",
              "      <td>0.343600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.323800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.407700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.372500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>435</td>\n",
              "      <td>0.340500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.469700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>445</td>\n",
              "      <td>0.401800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.370700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>455</td>\n",
              "      <td>0.349500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.332800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.348200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.397500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>0.318000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.355900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>485</td>\n",
              "      <td>0.413700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.323600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>495</td>\n",
              "      <td>0.413100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.342600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>505</td>\n",
              "      <td>0.299600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.376900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>515</td>\n",
              "      <td>0.390700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.346900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.364900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.330100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>535</td>\n",
              "      <td>0.346500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.378600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>545</td>\n",
              "      <td>0.421300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.459200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>555</td>\n",
              "      <td>0.427600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.295300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>565</td>\n",
              "      <td>0.365000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.440800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.459500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.341300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>585</td>\n",
              "      <td>0.376900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.387200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>595</td>\n",
              "      <td>0.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.319700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>605</td>\n",
              "      <td>0.281900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.386200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>615</td>\n",
              "      <td>0.322600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.337600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.313200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>635</td>\n",
              "      <td>0.338500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.329400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>645</td>\n",
              "      <td>0.331800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.331000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>655</td>\n",
              "      <td>0.333600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.320400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>665</td>\n",
              "      <td>0.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.346100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.355400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.346700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>685</td>\n",
              "      <td>0.382700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.336100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>695</td>\n",
              "      <td>0.408600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.392900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>705</td>\n",
              "      <td>0.333700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.392000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>715</td>\n",
              "      <td>0.343400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.341800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>0.319000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.334200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>735</td>\n",
              "      <td>0.288200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.270600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>745</td>\n",
              "      <td>0.292300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.275300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>755</td>\n",
              "      <td>0.269000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.289800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>765</td>\n",
              "      <td>0.269000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.332400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>0.311600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.252100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>785</td>\n",
              "      <td>0.289100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.249500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>795</td>\n",
              "      <td>0.269900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.321000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>805</td>\n",
              "      <td>0.330800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.291600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>815</td>\n",
              "      <td>0.317900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.307100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>0.265400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.246700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>835</td>\n",
              "      <td>0.347600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.291600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>845</td>\n",
              "      <td>0.262400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.280300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>855</td>\n",
              "      <td>0.271900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.280200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>865</td>\n",
              "      <td>0.276900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.319100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.276400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.305800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>885</td>\n",
              "      <td>0.285900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.325400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>895</td>\n",
              "      <td>0.325000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.308200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>905</td>\n",
              "      <td>0.307000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.355200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>915</td>\n",
              "      <td>0.239000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.285800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>0.271500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.329800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>935</td>\n",
              "      <td>0.277200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.280800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>945</td>\n",
              "      <td>0.329000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.285100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>955</td>\n",
              "      <td>0.221700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.273000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>965</td>\n",
              "      <td>0.229300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.251200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>0.316900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.290100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>985</td>\n",
              "      <td>0.234500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.274100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>995</td>\n",
              "      <td>0.284100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.256600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1005</td>\n",
              "      <td>0.418500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.244600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1015</td>\n",
              "      <td>0.319700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.272900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>0.338500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.349400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1035</td>\n",
              "      <td>0.276700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.302500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1045</td>\n",
              "      <td>0.291200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.307000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1055</td>\n",
              "      <td>0.304600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.260600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1065</td>\n",
              "      <td>0.256300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.200700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>0.283100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.281600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1085</td>\n",
              "      <td>0.283300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.245700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1095</td>\n",
              "      <td>0.266700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.315500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1105</td>\n",
              "      <td>0.287100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.315000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1115</td>\n",
              "      <td>0.247400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.266000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.273000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.244800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1135</td>\n",
              "      <td>0.272500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.270300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1145</td>\n",
              "      <td>0.243400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.316800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1155</td>\n",
              "      <td>0.271600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.295800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1165</td>\n",
              "      <td>0.323400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.270000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>0.284800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.310200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1185</td>\n",
              "      <td>0.270300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.247700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1195</td>\n",
              "      <td>0.265400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.237200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1205</td>\n",
              "      <td>0.295700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.249300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1215</td>\n",
              "      <td>0.293600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.342200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>0.305300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.248300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1235</td>\n",
              "      <td>0.276900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.286700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1245</td>\n",
              "      <td>0.270800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.223800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1255</td>\n",
              "      <td>0.298700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.272300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1265</td>\n",
              "      <td>0.225900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.185000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>0.255100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.284900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1285</td>\n",
              "      <td>0.266000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.309000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1295</td>\n",
              "      <td>0.316800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.275400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1305</td>\n",
              "      <td>0.224900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.263500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1315</td>\n",
              "      <td>0.320800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.243500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>0.221000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.292900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1335</td>\n",
              "      <td>0.259100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.266000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1345</td>\n",
              "      <td>0.268600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.348000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1355</td>\n",
              "      <td>0.265500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.226800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1365</td>\n",
              "      <td>0.268800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.244000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>0.323500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.316900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1385</td>\n",
              "      <td>0.296400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.251600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1395</td>\n",
              "      <td>0.255900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.210200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1405</td>\n",
              "      <td>0.225500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.307300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1415</td>\n",
              "      <td>0.263500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.276800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>0.347800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.273600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1435</td>\n",
              "      <td>0.277600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.282700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1445</td>\n",
              "      <td>0.286900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.258300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1455</td>\n",
              "      <td>0.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.350400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1462, training_loss=0.32893135468953283, metrics={'train_runtime': 1502.8876, 'train_samples_per_second': 0.973, 'train_steps_per_second': 0.973, 'total_flos': 9.893174124521472e+16, 'train_loss': 0.32893135468953283})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check if the model has learnt to follow the custom format:"
      ],
      "metadata": {
        "id": "DRMBNUBgLC8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    dataset[0][\"Messages\"][:2],\n",
        "    tokenize = False,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        ")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "_ = model.generate(\n",
        "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
        "    temperature = 0,\n",
        "    max_new_tokens = 1024,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
        ")"
      ],
      "metadata": {
        "id": "9HJxrS76h3Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f38538e-02d2-456a-cc41-0463934c1265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are given a problem.\n",
            "Think about the problem and provide your working out.\n",
            "Place it between <start_working_out> and <end_working_out>.\n",
            "Then, provide your solution between <SOLUTION></SOLUTION><|im_end|>Given $\\sqrt{x^2+165}-\\sqrt{x^2-52}=7$ and $x$ is positive, find all possible values of $x$.<start_working_out>Okay, let's see. I need to solve the equation ‚àö(x¬≤ + 165) - ‚àö(x¬≤ - 52) = 7, and x is positive. Hmm, square roots can be tricky, but maybe I can eliminate them by squaring both sides. Let me try that.\n",
            "\n",
            "First, let me rewrite the equation to make it a bit clearer. Let‚Äôs call the first square root as A and the second as B. So, A - B = 7. Then, if I square both sides, I get (A - B)¬≤ = 7¬≤, which is A¬≤ - 2AB + B¬≤ = 49.\n",
            "\n",
            "But A¬≤ is (x¬≤ + 165) and B¬≤ is (x¬≤ - 52). So substituting those in, we have:\n",
            "\n",
            "(x¬≤ + 165) - 2AB + (x¬≤ - 52) = 49.\n",
            "\n",
            "Combine like terms: x¬≤ + x¬≤ is 2x¬≤, 165 - 52 is 113. So:\n",
            "\n",
            "2x¬≤ + 113 - 2AB = 49.\n",
            "\n",
            "Subtract 49 from both sides:\n",
            "\n",
            "2x¬≤ + 113 - 49 = 2AB.\n",
            "\n",
            "Which simplifies to 2x¬≤ + 64 = 2AB.\n",
            "\n",
            "Divide both sides by 2:\n",
            "\n",
            "x¬≤ + 32 = AB.\n",
            "\n",
            "But AB is ‚àö(x¬≤ + 165) * ‚àö(x¬≤ - 52). So, x¬≤ + 32 = ‚àö[(x¬≤ + 165)(x¬≤ - 52)].\n",
            "\n",
            "Hmm, that still has a square root. Maybe I can square both sides again to eliminate the square root. Let's do that.\n",
            "\n",
            "Square both sides:\n",
            "\n",
            "(x¬≤ + 32)¬≤ = (x¬≤ + 165)(x¬≤ - 52).\n",
            "\n",
            "Expanding the left side: (x¬≤)¬≤ + 2*32*x¬≤ + 32¬≤ = x‚Å¥ + 64x¬≤ + 1024.\n",
            "\n",
            "Expanding the right side: (x¬≤)(x¬≤) + x¬≤*(-52) + 165*x¬≤ + 165*(-52) = x‚Å¥ -52x¬≤ +165x¬≤ -8580.\n",
            "\n",
            "Combine like terms on the right: x‚Å¥ + (165x¬≤ -52x¬≤) -8580 = x‚Å¥ +113x¬≤ -8580.\n",
            "\n",
            "So now the equation is:\n",
            "\n",
            "x‚Å¥ +64x¬≤ +1024 = x‚Å¥ +113x¬≤ -8580.\n",
            "\n",
            "Subtract x‚Å¥ from both sides:\n",
            "\n",
            "64x¬≤ +1024 = 113x¬≤ -8580.\n",
            "\n",
            "Bring all terms to one side:\n",
            "\n",
            "64x¬≤ -113x¬≤ +1024 +8580 = 0.\n",
            "\n",
            "Which simplifies to:\n",
            "\n",
            "-49x¬≤ +9604 = 0.\n",
            "\n",
            "Wait, 1024 +8580 is 9604? Let me check that. 1024 +8000 is 9024, plus 580 is 9604. Yes, that's correct.\n",
            "\n",
            "So:\n",
            "\n",
            "-49x¬≤ +9604 = 0.\n",
            "\n",
            "Add 49x¬≤ to both sides:\n",
            "\n",
            "9604 = 49x¬≤.\n",
            "\n",
            "Divide both sides by 49:\n",
            "\n",
            "x¬≤ = 9604 /49.\n",
            "\n",
            "Let me compute 9604 divided by 49. Hmm, 49*200 is 9800, which is 196 over. Wait, 49*200 is 9800, but 9604 is 196 less, so 49*(200 -196/49) Wait, maybe better to divide 9604 by 49. Let's do long division.\n",
            "\n",
            "49 into 9604. 49*196 = 49*200 -49*4 = 9800 -196 = 9604. So 49*196 =9604. Therefore, x¬≤=196. So x=‚àö196=14. But since x is positive, x=14.\n",
            "\n",
            "Wait, but let me check if this solution works in the original equation. Let's plug x=14 into the original equation.\n",
            "\n",
            "Left side: ‚àö(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes it did follow the formatting! Great! Let's remove some items before the GRPO step"
      ],
      "metadata": {
        "id": "AtZ3qGOALF95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del dataset\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWSZ0DET7bob",
        "outputId": "ef4cc296-c823-40ee-e744-cf9f7e90fd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "472"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KGgPgk_5S8r"
      },
      "source": [
        "### Data Prep\n",
        "<a name=\"Data\"></a>\n",
        "\n",
        "We're using Hugging Face's [Open R1 Math dataset](https://huggingface.co/datasets/open-r1/DAPO-Math-17k-Processed). You can also utilize OpenAI's famous [GSM8K dataset](https://huggingface.co/datasets/openai/gsm8k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7-eUrQn-OzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f862750-a540-4164-e33f-8ae4a8c0e8d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'solution', 'data_source', 'source_prompt', 'ability', 'reward_model', 'extra_info'],\n",
              "    num_rows: 14116\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"open-r1/DAPO-Math-17k-Processed\", \"en\", split = \"train\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b00gUsS-ROW"
      },
      "source": [
        "Let's look at the first row:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siopxjG8-ReF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2b54bd3f-b3ee-4f67-d956-8bc7fa741346"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In triangle $ABC$, $\\\\sin \\\\angle A = \\\\frac{4}{5}$ and $\\\\angle A < 90^\\\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\\\angle BAD = \\\\angle DAC$ and $\\\\angle BDC = 90^\\\\circ$. Suppose that $AD = 1$ and that $\\\\frac{BD}{CD} = \\\\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\\\frac{a\\\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "dataset[0][\"prompt\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGupRQqD-Wcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8a48622-0a0b-43ef-c846-07eff2621ce2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'34'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset[0][\"solution\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmnXj6hn-Ydi"
      },
      "source": [
        "In GSM8K, ee notice all answers like about have a ####, so we extract it. But for the Open R1 dataset, we can skip the below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JJGXKdJ-Zl_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0cfac306-fed7-4495-a265-ff95c1e82818"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'34'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "def extract_hash_answer(text):\n",
        "    # if \"####\" not in text: return None\n",
        "    # return text.split(\"####\")[1].strip()\n",
        "    return text\n",
        "extract_hash_answer(dataset[0][\"solution\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K30CygaU-dir"
      },
      "source": [
        "Let's map the dataset! and see the first row:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyEVI972-d3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e747447-e4b0-49bb-a857-8c02519da714"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': [{'content': 'You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION>',\n",
              "   'role': 'system'},\n",
              "  {'content': 'In triangle $ABC$, $\\\\sin \\\\angle A = \\\\frac{4}{5}$ and $\\\\angle A < 90^\\\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\\\angle BAD = \\\\angle DAC$ and $\\\\angle BDC = 90^\\\\circ$. Suppose that $AD = 1$ and that $\\\\frac{BD}{CD} = \\\\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\\\frac{a\\\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.',\n",
              "   'role': 'user'}],\n",
              " 'solution': '34',\n",
              " 'data_source': 'math_dapo',\n",
              " 'source_prompt': [{'content': 'Solve the following math problem step by step. The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.\\n\\nIn triangle $ABC$, $\\\\sin \\\\angle A = \\\\frac{4}{5}$ and $\\\\angle A < 90^\\\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\\\angle BAD = \\\\angle DAC$ and $\\\\angle BDC = 90^\\\\circ$. Suppose that $AD = 1$ and that $\\\\frac{BD}{CD} = \\\\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\\\frac{a\\\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.\\n\\nRemember to put your answer on its own line after \"Answer:\".',\n",
              "   'role': 'user'}],\n",
              " 'ability': 'MATH',\n",
              " 'reward_model': {'ground_truth': '34', 'style': 'rule-lighteval/MATH_v2'},\n",
              " 'extra_info': {'index': '9a9b6eb4-a1cb-49d1-8c1e-62eaf2f74079'},\n",
              " 'answer': '34'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "dataset = dataset.map(lambda x: {\n",
        "    \"prompt\" : [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\",   \"content\": x[\"prompt\"]},\n",
        "    ],\n",
        "    \"answer\": extract_hash_answer(x[\"solution\"]),\n",
        "})\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9m8eR9T-gMh"
      },
      "source": [
        "We create a regex format to match the reasoning sections and answers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQwjTjNz-gY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9631fd1-a585-427c-abac-9cf0f122b959"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "re.compile(r'<end_working_out>.*?<SOLUTION>(.+?)</SOLUTION>[\\s]{0,}(?:<\\|im_end\\|>)?[\\s]{0,}$',\n",
              "re.MULTILINE|re.DOTALL|re.UNICODE)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Add optional EOS token matching\n",
        "solution_end_regex = r\"</SOLUTION>[\\s]{0,}\" + \\\n",
        "    \"(?:\" + re.escape(tokenizer.eos_token) + \")?\"\n",
        "\n",
        "match_format = re.compile(\n",
        "    rf\"{reasoning_end}.*?\"\\\n",
        "    rf\"{solution_start}(.+?){solution_end_regex}\"\\\n",
        "    rf\"[\\s]{{0,}}$\",\n",
        "    flags = re.MULTILINE | re.DOTALL\n",
        ")\n",
        "match_format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OycMneOq-iNC"
      },
      "source": [
        "We verify it works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndzHnQ_6-jHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7961e06e-a22d-41ed-fa93-82a7ffe499e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n2\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "match_format.findall(\n",
        "    \"Let me think!<end_working_out>\"\\\n",
        "    f\"<SOLUTION>\\n2\\n</SOLUTION>\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_format.findall(\n",
        "    \"<start_working_out>Let me think!<end_working_out>\"\\\n",
        "    f\"<SOLUTION>  2  </SOLUTION>\\n\\n\",\n",
        ")"
      ],
      "metadata": {
        "id": "eRMDAzDk2x6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68d59c0-d94f-4588-c4e1-d6feb05b7dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  2  ']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weOjmO5l-kl3"
      },
      "source": [
        "We now want to create a reward function to match the format exactly - we reward it with 3 points if it succeeds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgFNXORy-lpO"
      },
      "outputs": [],
      "source": [
        "def match_format_exactly(completions, **kwargs):\n",
        "    scores = []\n",
        "    for completion in completions:\n",
        "        score = 0\n",
        "        response = completion[0][\"content\"]\n",
        "        # Match if format is seen exactly!\n",
        "        if match_format.search(response) is not None: score += 3.0\n",
        "        scores.append(score)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf69i2WT-m4K"
      },
      "source": [
        "If it fails, we want to reward the model if it at least follows the format partially, by counting each symbol:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUfHzCVx-nGK"
      },
      "outputs": [],
      "source": [
        "def match_format_approximately(completions, **kwargs):\n",
        "    scores = []\n",
        "    for completion in completions:\n",
        "        score = 0\n",
        "        response = completion[0][\"content\"]\n",
        "        # Count how many keywords are seen - we penalize if too many!\n",
        "        # If we see 1, then plus some points!\n",
        "\n",
        "        # No need to reward <start_working_out> since we always prepend it!\n",
        "        # score += 0.5 if response.count(reasoning_start) == 1 else -1.0\n",
        "        score += 0.5 if response.count(reasoning_end)   == 1 else -1.0\n",
        "        score += 0.5 if response.count(solution_start)  == 1 else -1.0\n",
        "        score += 0.5 if response.count(solution_end)    == 1 else -1.0\n",
        "        scores.append(score)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wAUWwtE-s6n"
      },
      "source": [
        "Finally, we want to extract the generated answer, and reward or penalize it! We also reward it based on how close the answer is to the true one via ratios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmtI_8gg-uIE"
      },
      "outputs": [],
      "source": [
        "def check_answer(prompts, completions, answer, **kwargs):\n",
        "    question = prompts[0][-1][\"content\"]\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    extracted_responses = [\n",
        "        guess.group(1)\n",
        "        if (guess := match_format.search(r)) is not None else None \\\n",
        "        for r in responses\n",
        "    ]\n",
        "\n",
        "    scores = []\n",
        "    for guess, true_answer in zip(extracted_responses, answer):\n",
        "        score = 0\n",
        "        if guess is None:\n",
        "            scores.append(-2.0)\n",
        "            continue\n",
        "        # Correct answer gets 5 points!\n",
        "        if guess == true_answer:\n",
        "            score += 5.0\n",
        "        # Match if spaces are seen, but less reward\n",
        "        elif guess.strip() == true_answer.strip():\n",
        "            score += 3.5\n",
        "        else:\n",
        "            # We also reward it if the answer is close via ratios!\n",
        "            # Ie if the answer is within some range, reward it!\n",
        "            try:\n",
        "                ratio = float(guess) / float(true_answer)\n",
        "                if   ratio >= 0.9 and ratio <= 1.1: score += 2.0\n",
        "                elif ratio >= 0.8 and ratio <= 1.2: score += 1.5\n",
        "                else: score -= 2.5 # Penalize wrong answers\n",
        "            except:\n",
        "                score -= 4.5 # Penalize\n",
        "        scores.append(score)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atMyfhXh-v3R"
      },
      "source": [
        "Also sometimes it might not be 1 number as the answer, but like a sentence for example \"The solution is $20\" -> we extract 20.\n",
        "\n",
        "We also remove possible commas for example as in 123,456"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVW0kL8q-wL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13d6ea5-6dd1-457f-c025-fbbdc7eca915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0.34']\n",
            "['123,456']\n",
            "['-0.234']\n",
            "['17']\n"
          ]
        }
      ],
      "source": [
        "match_numbers = re.compile(\n",
        "    solution_start + r\".*?[\\s]{0,}([-]?[\\d\\.\\,]{1,})\",\n",
        "    flags = re.MULTILINE | re.DOTALL\n",
        ")\n",
        "print(match_numbers.findall(\"<SOLUTION>  0.34  </SOLUTION>\"))\n",
        "print(match_numbers.findall(\"<SOLUTION>  123,456  </SOLUTION>\"))\n",
        "print(match_numbers.findall(\"<SOLUTION>  -0.234  </SOLUTION>\"))\n",
        "print(match_numbers.findall(\"<SOLUTION>17</SOLUTION>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now prepare our main function which will print out the generated responses and the true answer, along with another reward function which converts text to float via `float` and sees if it's the same."
      ],
      "metadata": {
        "id": "RbfaaAywNHHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjBFrttr-y1_"
      },
      "outputs": [],
      "source": [
        "global PRINTED_TIMES\n",
        "PRINTED_TIMES = 0\n",
        "global PRINT_EVERY_STEPS\n",
        "PRINT_EVERY_STEPS = 5\n",
        "\n",
        "def check_numbers(prompts, completions, answer, **kwargs):\n",
        "    question = prompts[0][-1][\"content\"]\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    extracted_responses = [\n",
        "        guess.group(1)\n",
        "        if (guess := match_numbers.search(r)) is not None else None \\\n",
        "        for r in responses\n",
        "    ]\n",
        "\n",
        "    scores = []\n",
        "    # Print only every few steps\n",
        "    global PRINTED_TIMES\n",
        "    global PRINT_EVERY_STEPS\n",
        "    if PRINTED_TIMES % PRINT_EVERY_STEPS == 0:\n",
        "        print(\n",
        "            '*'*20 + f\"Question:\\n{question}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\"\n",
        "        )\n",
        "    PRINTED_TIMES += 1\n",
        "\n",
        "    for guess, true_answer in zip(extracted_responses, answer):\n",
        "        if guess is None:\n",
        "            scores.append(-2.5)\n",
        "            continue\n",
        "        # Convert to numbers\n",
        "        try:\n",
        "            true_answer = float(true_answer.strip())\n",
        "            # Remove commas like in 123,456\n",
        "            guess       = float(guess.strip().replace(\",\", \"\"))\n",
        "            scores.append(3.5 if guess == true_answer else -1.5)\n",
        "        except:\n",
        "            scores.append(0)\n",
        "            continue\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgOR3wJ_AyLr"
      },
      "source": [
        "Get the top 90% prompt length so we don't accidentally truncate them!\n",
        "\n",
        "Ie we'll remove the top 10% long prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EgAi4Q5fGE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f530eb23-e7e1-4aba-d814-8e9d9e960221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are given a problem.\n",
            "Think about the problem and provide your working out.\n",
            "Place it between <start_working_out> and <end_working_out>.\n",
            "Then, provide your solution between <SOLUTION></SOLUTION><|im_end|>In triangle $ABC$, $\\sin \\angle A = \\frac{4}{5}$ and $\\angle A < 90^\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\angle BAD = \\angle DAC$ and $\\angle BDC = 90^\\circ$. Suppose that $AD = 1$ and that $\\frac{BD}{CD} = \\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\frac{a\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.<start_working_out>\n",
            "Max Length =  201\n"
          ]
        }
      ],
      "source": [
        "tokenized = dataset.map(\n",
        "    lambda x: {\"tokens\" : tokenizer.apply_chat_template(x[\"prompt\"], add_generation_prompt = True, tokenize = True)},\n",
        "    batched = True,\n",
        ")\n",
        "print(tokenizer.decode(tokenized[0][\"tokens\"]))\n",
        "tokenized = tokenized.map(lambda x: {\"L\" : len(x[\"tokens\"])})\n",
        "\n",
        "import numpy as np\n",
        "maximum_length = int(np.quantile(tokenized[\"L\"], 0.9))\n",
        "print(\"Max Length = \", maximum_length)\n",
        "\n",
        "# Filter only samples smaller than 90% max length\n",
        "dataset = dataset.select(np.where(np.array(tokenized[\"L\"]) <= maximum_length)[0])\n",
        "del tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-IOMhVg-2AM"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "\n",
        "Now set up GRPO Trainer and all configurations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptqkXK2D4d6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b51b1ca-0d68-4f4b-c34b-8f962d0861c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
            "We will change the batch size of 1 to the `num_generations` of 4\n"
          ]
        }
      ],
      "source": [
        "max_prompt_length = maximum_length + 1 # + 1 just in case!\n",
        "max_completion_length = max_seq_length - max_prompt_length\n",
        "\n",
        "from vllm import SamplingParams\n",
        "vllm_sampling_params = SamplingParams(\n",
        "    min_p = 0.1,\n",
        "    top_p = 1.0,\n",
        "    top_k = -1,\n",
        "    seed = 3407,\n",
        "    stop = [tokenizer.eos_token],\n",
        "    include_stop_str_in_output = True,\n",
        ")\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    vllm_sampling_params = vllm_sampling_params,\n",
        "    temperature = 1.0,\n",
        "    learning_rate = 5e-6,\n",
        "    weight_decay = 0.01,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    optim = \"adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 4, # Decrease if out of memory\n",
        "    max_prompt_length = max_prompt_length,\n",
        "    max_completion_length = max_completion_length,\n",
        "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
        "    max_steps = 100,\n",
        "    save_steps = 100,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        "\n",
        "    # For optional training + evaluation\n",
        "    # fp16_full_eval = True,\n",
        "    # per_device_eval_batch_size = 4,\n",
        "    # eval_accumulation_steps = 1,\n",
        "    # eval_strategy = \"steps\",\n",
        "    # eval_steps = 1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Mv8UZO5hz-"
      },
      "source": [
        "And let's run the trainer! If you scroll up, you'll see a table of rewards. The goal is to see the `reward` column increase!\n",
        "\n",
        "You might have to wait 150 to 200 steps for any action. You'll probably get 0 reward for the first 100 steps. Please be patient!\n",
        "\n",
        "| Step | Training Loss | reward    | reward_std | completion_length | kl       |\n",
        "|------|---------------|-----------|------------|-------------------|----------|\n",
        "| 1    | 0.000000      | 0.125000  | 0.000000   | 200.000000        | 0.000000 |\n",
        "| 2    | 0.000000      | 0.072375  | 0.248112   | 200.000000        | 0.000000 |\n",
        "| 3    | 0.000000      | -0.079000 | 0.163776   | 182.500000        | 0.000005 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzOuSVCL_GA9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f70fe6d-9673-4221-ec32-e021b58c6bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 12,709 | Num Epochs = 1 | Total steps = 100\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
            " \"-____-\"     Trainable parameters = 32,112,640/14,000,000,000 (0.23% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************Question:\n",
            "Compute the number of positive integers that divide at least two of the integers in the set $\\{1^1,2^2,3^3,4^4,5^5,6^6,7^7,8^8,9^9,10^{10}\\}$. \n",
            "Answer:\n",
            "22 \n",
            "Response:\n",
            "Okay, so I need to find how many positive integers divide at least two of the numbers in this set: 1^1, 2^2, 3^3, up to 10^10. Hmm, let's see. First, maybe I should just list out what each term is.\n",
            "\n",
            "Starting with 1^1, that's just 1. Then 2 squared is 4, 3 cubed is 27, 4^4 is 256, 5^5 is 3125, 6^6 is 46656, 7^7 I think is 823543, 8^8 is 16777216. Then 9^9 is a really big number, 387420489, and 10^10 is 10000000000. Okay, so each number is a base raised to that base. So, numbers like 1, 4, 27, 256, etc.\n",
            "\n",
            "The problem is asking for numbers that divide at least two of these. So, if a divisor d divides, say, 4 and 27, then d has to be a common divisor of those two. But wait, 4 and 27 are coprime because 4 is 2^2 and 27 is 3^3. Wait, is that right? Wait, 4 is 2^2 and 27 is 3^3. So their greatest common divisor is 1. So, their only common divisor is 1. Therefore, the only divisor that divides both 4 and 27 is 1. So 1 is a divisor of all numbers in the set, but the question says \"divides at least two of the integers\". So 1 divides all of them, but maybe that's allowed? So the answer would include 1?\n",
            "\n",
            "But wait, maybe there are other numbers that divide two or more of these numbers. For example, take 2^2 and 4^4. 4^4 is (2^2)^2 = 2^8. So both 2^2 and 2^8 share common divisors like 1, 2^1, 2^2. So their common divisors are 1, 2, 4. So those numbers divide both 4 and 256. So 2 and 4 would be included. But I need to check if any numbers divide at least two numbers in the entire set.\n",
            "\n",
            "This seems tedious. Maybe there's a smarter way. Let's think about prime factors. If two numbers share a prime factor, their common divisors come from the intersection of their prime factors. For example, take 2^2 and 3^3. They have no common primes, so only 1. But 2^2 and 4^4 are both powers of 2. So their common divisors are the divisors of 2^2, which are 1, 2, 4. Similarly, 3^3 and 9^9: 9 is 3^2, so 9^9 is 3^(2*9)=3^18. So the common divisors here would be the divisors of 3^3, which are 1, 3, 9, 27. So 3, 9, 27 are divisors of both 27 and 387420489 (9^9).\n",
            "\n",
            "Wait, so if two numbers have the same base, then their common divisors are the divisors of the smaller exponent? Let me check. Suppose we take 2^2 and 2^4. The exponents are 2 and 4. The common exponent would be the minimum, which is 2. So divisors of 2^2 are 1, 2, 4. For 3^3 and 3^9, common divisors would be 1, 3, 9, 27. So in general, if the base is the same, the common divisors are the divisors of the base raised to the smaller exponent.\n",
            "\n",
            "So maybe the strategy here is to group the numbers by their base, since numbers with the same base will have common divisors. For example, all numbers with base 2: 2^2 and 8^8. Wait, 8 is 2^3, so 8^8 is (2^3)^8 = 2^24. So the common divisors of 2^2 and 2^24 would be 1, 2, 4. Similarly, base 3: 3^3 and 9^9. 9 is 3^2, so 9^9 is 3^18. So common divisors of 3^3 and 3^18 are 1, 3, 9, 27. Similarly, base 4: 4^4 is (2^2)^4 = 2^8. Then another number with base 4? But base 4 would be 4^4. So only one number with base 4. Then base 5: 5^5, no other base 5. Similarly, base 6: 6^6. Another base 6? Only one. Base 7: 7^7, base 8: another 2^3 base. Wait, 8^8. So same as base 2. Then base 9: 9^9, base 10: 10^10.\n",
            "\n",
            "So, group them by base. Then within each group where there are two or more numbers with the same base, the common divisors would be the divisors of the number with the smaller exponent. But wait, because 1^1 is in the set. Wait, 1^1 is 1. So 1 divides every number. So maybe I need to consider that 1 is a divisor of all, but the question is asking for numbers that divide at least two of the integers. So 1 divides all of them, so 1 is included. But then, also numbers that are divisors of two or more numbers. So the answer would be the union of all the divisors of pairs of numbers in the set.\n",
            "\n",
            "But maybe there's overlap. For instance, maybe a number like 2 divides 4 and 8^8. Since 4 is 2^2 and 8^8 is (2^3)^8 = 2^24, so 2 is a common divisor. Similarly, 2^k where k <= 2, so 1, 2, 4. Wait, but if you have numbers like 2^2 and 8^8, the common divisors are 1, 2, 4. So how many divisors do we have? For each group where the base is the same and there are at least two numbers, we take the divisors of the number with the smaller exponent. Then take the union over all such groups. Then add 1 if it's included.\n",
            "\n",
            "So let's list out the bases and see how many numbers share the same base.\n",
            "\n",
            "Wait, the numbers in the set are 1^1, 2^2, 3^3, 4^4, 5^5, 6^6, 7^7, 8^8, 9^9, 10^10.\n",
            "\n",
            "But 4^4 is 256, which is 4^4. Then 8^8 is 2^24. But 4 is 2^2, so when we have base 2, which numbers have base 2? 2^2 is base 2, 4^4 is also base 4, but 4 is 2^2, so 4^4 is (2^2)^4 = 2^8. 8^8 is base 8, which is 2^3. Wait, maybe it's better to factor each number into primes to see their prime factorizations.\n",
            "\n",
            "Let me list all the numbers in the set with their prime factorizations:\n",
            "\n",
            "1^1 = 1 (no prime factors)\n",
            "2^2 = 4 = 2^2\n",
            "3^3 = 27 = 3^3\n",
            "4^4 = 256 = (2^2)^4 = 2^8\n",
            "5^5 = 3125 = 5^5\n",
            "6^6 = (2*3)^6 = 2^ \n",
            "Extracted:\n",
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 20/100 51:39 < 3:49:35, 0.01 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completion_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / match_format_exactly</th>\n",
              "      <th>rewards / match_format_approximately</th>\n",
              "      <th>rewards / check_answer</th>\n",
              "      <th>rewards / check_numbers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.008400</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.210673</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.008500</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.213404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.010200</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.253885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.005600</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.140083</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.007300</td>\n",
              "      <td>1.875000</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.181993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.006400</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.160326</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.009500</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.238294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.007200</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.180507</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.008400</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.209636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.144027</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.010600</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.264008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.008600</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.216019</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.008900</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.223701</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.009000</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.224783</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.006200</td>\n",
              "      <td>-3.500000</td>\n",
              "      <td>5.049752</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.153837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.005700</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.142830</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.006200</td>\n",
              "      <td>-4.875000</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.154364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.875000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.007300</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1846.000000</td>\n",
              "      <td>0.181376</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************Question:\n",
            "The sum of $\\lfloor x \\rfloor$ for all real numbers $x$ satisfying the equation $16 + 15x + 15x^2 = \\lfloor x \\rfloor^3$ is: \n",
            "Answer:\n",
            "33 \n",
            "Response:\n",
            "Okay, let me try to figure out this problem. So, the equation is 16 + 15x + 15x¬≤ = floor(x)¬≥. We need to find all real numbers x that satisfy this equation and then compute the sum of their floor values. Hmm, floor(x) is the greatest integer less than or equal to x. Let me denote floor(x) as n, where n is an integer. Then, x is in the interval [n, n+1). \n",
            "\n",
            "Substituting floor(x) = n into the equation, we get:\n",
            "\n",
            "16 + 15x + 15x¬≤ = n¬≥.\n",
            "\n",
            "Since n is an integer, maybe I can consider possible values of n and see for which ones there is a solution for x in [n, n+1). Let me try plugging in some integers for n and check.\n",
            "\n",
            "First, let's recall that x is between n and n+1. So x = t + n, where t ‚àà [0, 1). Maybe substituting x = t + n into the equation makes sense.\n",
            "\n",
            "Alternatively, maybe solving the quadratic equation for x in terms of n. Let me try that.\n",
            "\n",
            "Original equation: 16 + 15x + 15x¬≤ = n¬≥.\n",
            "\n",
            "Rearranged: 15x¬≤ + 15x + (16 - n¬≥) = 0.\n",
            "\n",
            "This is a quadratic in x. So using the quadratic formula:\n",
            "\n",
            "x = [ -b ¬± ‚àö(b¬≤ - 4ac) ] / (2a)\n",
            "\n",
            "Here, a = 15, b = 15, c = 16 - n¬≥.\n",
            "\n",
            "Discriminant D = b¬≤ - 4ac = (15)¬≤ - 4*15*(16 - n¬≥) = 225 - 60(16 - n¬≥) = 225 - 960 + 60n¬≥ = 60n¬≥ - 735.\n",
            "\n",
            "So, D = 60n¬≥ - 735.\n",
            "\n",
            "For real solutions, D >= 0. So 60n¬≥ - 735 >= 0 => 60n¬≥ >= 735 => n¬≥ >= 735/60 => n¬≥ >= 12.25.\n",
            "\n",
            "Since n is an integer, let's find the smallest integer n such that n¬≥ >= 12.25. 2¬≥ = 8 < 12.25, 3¬≥ = 27 >= 12.25. So starting from n=3 upwards.\n",
            "\n",
            "But wait, maybe n can also be negative. Let me check. For negative n, n¬≥ is negative, so 60n¬≥ -735 would be negative. Then D would be negative, no real solutions. So perhaps n is a non-negative integer starting from 3.\n",
            "\n",
            "Let me check n=3:\n",
            "\n",
            "x¬≤ + x + (16 - 27)/15 = x¬≤ + x - 11/15 = 0.\n",
            "\n",
            "Quadratic equation: x = [ -1 ¬± sqrt(1 - 4*(1)*( -11/15)) ] / 2 = [ -1 ¬± sqrt(1 + 44/15) ] / 2 = [ -1 ¬± sqrt(59/15) ] / 2.\n",
            "\n",
            "Wait, sqrt(59/15) is ~ sqrt(3.9333) ‚âà 1.983.\n",
            "\n",
            "So x ‚âà (-1 ¬±1.983)/2. The two solutions would be approximately (-1 +1.983)/2 ‚âà 0.983 and (-1 -1.983)/2 ‚âà -1.4915.\n",
            "\n",
            "But if n=3, x is in [3,4). The solution x‚âà0.983 is in [0,1), which contradicts n=3. So perhaps no solution for n=3.\n",
            "\n",
            "Wait, maybe I made a mistake. Let me go back.\n",
            "\n",
            "For n=3: x must satisfy 3 ‚â§ x <4. But when solving the quadratic, the solutions were around 0.983 and -1.4915, neither of which is in [3,4). So no solution for n=3.\n",
            "\n",
            "Wait, maybe n=2.\n",
            "\n",
            "Check n=2:\n",
            "\n",
            "Then the equation becomes 16 +15x +15x¬≤ = 8.\n",
            "\n",
            "So 15x¬≤ +15x +16 -8 =0 => 15x¬≤ +15x +8 =0.\n",
            "\n",
            "D = (15)¬≤ -4*15*8 = 225 - 480 = -255. Negative discriminant, no real solutions. So n=2 is invalid.\n",
            "\n",
            "n=1:\n",
            "\n",
            "15x¬≤ +15x +16 -1 =0 => 15x¬≤ +15x +15 =0 => x¬≤ +x +1=0.\n",
            "\n",
            "D = 1 -4 = -3. No real solutions. So n=1 invalid.\n",
            "\n",
            "n=0:\n",
            "\n",
            "15x¬≤ +15x +16 -0 =0 => 15x¬≤ +15x +16 =0.\n",
            "\n",
            "D = 225 -4*15*16=225 -960=-735. No solutions. So n=0 invalid.\n",
            "\n",
            "n=4:\n",
            "\n",
            "Then equation: 16 +15x +15x¬≤=64.\n",
            "\n",
            "15x¬≤ +15x +16 -64=0=>15x¬≤ +15x -48=0.\n",
            "\n",
            "Divide by 3: 5x¬≤ +5x -16=0.\n",
            "\n",
            "Discriminant: 25 +320=345. sqrt(345)‚âà18.574.\n",
            "\n",
            "Solutions: x= [-5 ¬±18.574]/10\n",
            "\n",
            "So (-5 +18.574)/10‚âà13.574/10‚âà1.3574,\n",
            "\n",
            "(-5 -18.574)/10‚âà-23.574/10‚âà-2.3574.\n",
            "\n",
            "Since n=4, x needs to be in [4,5), but 1.3574 is in [1,2), so no solution here. So n=4 is invalid.\n",
            "\n",
            "n=5:\n",
            "\n",
            "16 +15x +15x¬≤=125.\n",
            "\n",
            "15x¬≤ +15x +16 -125=0 =>15x¬≤ +15x -109=0.\n",
            "\n",
            "Divide by 5: 3x¬≤ +3x -109/5=0.\n",
            "\n",
            "Multiply by 5 to eliminate denominator: 15x¬≤ +15x -109=0.\n",
            "\n",
            "Discriminant: 225 - 4*15*(-109)=225 + 6540=6765.\n",
            "\n",
            "sqrt(6765)‚âà82.25.\n",
            "\n",
            "Solutions: x= [-15 ¬±82.25]/30.\n",
            "\n",
            "So (-15 +82.25)/30‚âà67.25/30‚âà2.2417,\n",
            "\n",
            "(-15 -82.25)/30‚âà-97.25/30‚âà-3.2417.\n",
            "\n",
            "n=5 requires x in [5,6). But 2.2417 is in [2,3), so no solution.\n",
            "\n",
            "Similarly, higher n will result in x much larger, but not in [n, n+1). So perhaps there are no solutions. Wait, but maybe I made an error in process.\n",
            "\n",
            "Wait, another approach. Since floor(x) is n, x = t + n where 0 ‚â§ t <1.\n",
            "\n",
            "Plugging into equation: 16 +15(t +n) +15(t +n)^2 = n¬≥.\n",
            "\n",
            "Expanding:\n",
            "\n",
            "16 +15t +15n +15(t¬≤ +2nt +n¬≤) = n¬≥.\n",
            "\n",
            "Combine like terms:\n",
            "\n",
            "16 +15n +15t +15t¬≤ +30nt +15n¬≤ = n¬≥.\n",
            "\n",
            "Hmm, this seems complicated. Maybe grouping terms with t:\n",
            "\n",
            "15t¬≤ + (15 +30n)t + (16 +15n +15 \n",
            "Extracted:\n",
            "None\n",
            "********************Question:\n",
            "Letters $A, B, C,$ and $D$ represent four different digits from 0, 1, 2, 3, ..., 9. If $\\frac{A+B}{C+D}$ is an integer that is as large as possible, what is the value of $A+B$? \n",
            "Answer:\n",
            "17 \n",
            "Response:\n",
            "Okay, so I have this problem where letters A, B, C, and D represent four different digits from 0 to 9. I need to find the value of A+B such that (A+B)/(C+D) is as large as possible and is an integer. Let me try to break this down.\n",
            "\n",
            "First, since we're dealing with digits, each letter is a number from 0 to 9, and all four letters must be different. The expression (A+B)/(C+D) needs to be an integer, and we want this integer to be as large as possible. The larger the integer result, the bigger A+B must be compared to C+D. But we need to ensure that A+B and C+D are both numbers that can be formed by adding two distinct digits from 0-9.\n",
            "\n",
            "What's the maximum possible value of (A+B)/(C+D)? Let's think about the denominator (C+D). To maximize the quotient, we want to make the denominator as small as possible. The smallest possible sum of two distinct digits is 1+0=1. But then, can C be 0 and D be 1? But wait, even if we let C and D be 0 and 1, which sum to 1, then A+B would have to be a multiple of 1. Since any integer divided by 1 is itself. However, A and B must also be different digits, not equal to C or D. So if C and D are 0 and 1, then A and B can't be 0 or 1. So the smallest possible denominator is 1, but that might not allow A and B to be large enough. But wait, maybe there's another small denominator.\n",
            "\n",
            "Wait, the next possible small denominators would be 2 (1+1, but digits can't repeat, so 1+1 is not allowed. Then 1+0=1, but we already saw that. Then the next possible denominator is 3 (like 0+3 or 1+2). Let's check.\n",
            "\n",
            "But maybe we should start by trying the largest possible possible (A+B) divided by the smallest possible (C+D). Let's suppose (C+D) is 1. Then A+B can be any multiple of 1, but since A and B are digits, the maximum possible A+B is 9+8=17. But if the denominator is 1, then (A+B)/1 = A+B, which can be up to 17. But are there constraints? The digits must all be distinct. So if C and D are 0 and 1, then A can be 2-9 and B is another distinct digit. Wait, but if C=0 and D=1, then A and B can't be 0 or 1. So A can be 2-9, B can be 2-9 but different from A. So maximum A+B would be 9 + 8 = 17. So in this case, the quotient is 17/1 = 17. But we have to check if higher denominators give a larger integer quotient.\n",
            "\n",
            "Wait, but if the denominator is 2, then the quotient would need to be an integer. So (A+B)/2 needs to be integer, so A+B must be even, and the maximum possible even sum of two distinct digits. The maximum even sum is 8 + 6 = 14? Let me check: 9 + 7 = 16, which is odd. Then 9 + 5 = 14 (no, 9 +5 is 14 but digits used are 9 and 5. So 9+5=14, which is even. Then 9+7=16, which is also even, but 7 is used as B. But if denominator is 2, then C and D must be 0 and 1, so digits used in denominator are 0 and 1. Then A and B can be 2,3,4,5,6,7,8,9. So 9+7=16 is possible, since 7 is a digit not used in C and D. So then the quotient would be 16/2=8. That's smaller than 17. So denominator 1 gives 17, denominator 2 gives 8. So denominator 1 is better.\n",
            "\n",
            "But wait, can we get a denominator 1? Let's confirm: Let's set C=0 and D=1. Then (C+D)=1. So (A+B)/1 must be integer, which means A+B is integer (which it always is). Then the maximum possible A+B would be 9+8=17. But we have to ensure that all four digits are distinct. So C=0, D=1, A=9, B=8. Then digits used: 0,1,9,8. All different. So that's valid. Then (A+B)/(C+D)=17/1=17. So that's the maximum possible.\n",
            "\n",
            "But wait, let me check if there's another combination where denominator is larger but quotient is still integer. For example, maybe denominator is 3, then quotient must be an integer like 5, 6, etc. So if denominator is 3, then A+B can be 3*5=15? Wait, 15/3=5. But max A+B can be when denominator is 3. If denominator is sum of two digits equal to 3, like 0+3. Then A+B needs to be multiple of 3. The maximum possible A+B here would be 9+8=17, but 17/3 is not integer. The next possible multiple of 3 would be 15. So if A+B=15, which is 8+7=15, then digits used: 8,7. Then C and D would be 0 and 3. So digits: 0,3,8,7. All different. Then (A+B)/(C+D)=15/3=5. Which is smaller than 17. So denominator 3 gives 5. So that's worse.\n",
            "\n",
            "Similarly, denominator 4: sum of two digits =4, like 0+4. Then A+B must be multiple of 4. The maximum possible A+B here is 9+8=17. But 17 divided by 4 is 4.25, not integer. Next multiple of 4 is 16, which is 8+8, but digits can't repeat. Next is 12, 5+7=12 or 6+6, no. So denominator 4 would require C+D=4. Then possible C,D are (0,4), (1,3). Then A,B would be digits not used in C and D. So for example, if C=0, D=4, then A,B can be 1-2,5-9. The maximum A+B here would be 9+5=14. 14/4=3.5, not integer. Next multiple of 4: 12, 5+7=12. So 5 and 7. Check: C=0, D=4, so A=5, B=7. Then (A+B) is 12, divided by 4 gives 3. So 12/4=3. Then the quotient is 3. Which is smaller than 17.\n",
            "\n",
            "So denominator 1 gives the highest quotient. Therefore, the maximum value of (A+B)/(C+D) is 17, when A+B=17 and C+D=1. So A+B is 17. Therefore, the answer is 17.\n",
            "\n",
            "Wait, is there a possibility where denominator is larger but quotient is higher? For example, maybe denominator 5. Let's check. Sum of two distinct digits equal to 5: 0+5, 1+4, 2+3. Let's take C+D=5. Then A+B must be a multiple of 5. The maximum possible A+B here would be 9+8=17. 17 divided by 5 is 3.4, not integer. Next multiple of 5 is 15. 15/5=3. So if A+B=15, which can be 7+8=15. Check digits: if C,D are 1,4, then A=7, B=8. So digits: 1,4,7,8. \n",
            "Extracted:\n",
            "None\n",
            "********************Question:\n",
            "Let $f(x)=\\int_0^{x} e^{t} (\\cos t+\\sin t)\\, dt$, $g(x)=\\int_0^{x} e^{t} (\\cos t-\\sin t)\\, dt$. \n",
            "\n",
            "For a real number $a$, find:\n",
            "\\[ \\sum_{n=1}^{\\infty} \\frac{e^{2a}}{\\{f^{(n)}(a)\\}^2+\\{g^{(n)}(a)\\}^2}. \\] \n",
            "Answer:\n",
            "1 \n",
            "Response:\n",
            "Okay, so I need to solve this problem where I have to evaluate the sum from n=1 to infinity of e^(2a) divided by the square of f^(n)(a) plus the square of g^(n)(a). The functions f(x) and g(x) are defined as integrals from 0 to x of e^t (cos t + sin t) dt and e^t (cos t - sin t) dt, respectively. Hmm, integrals involving exponentials and trigonometric functions... Maybe I can find a closed-form expression for f(x) and g(x) first. Let's see.\n",
            "\n",
            "Starting with f(x). The integral is of e^t (cos t + sin t) dt. That looks like it's the integral of the derivative of something. Let me check if (e^t cos t) is the derivative of e^t (cos t + sin t). Wait, no, let's compute the derivative of e^t cos t. Using the product rule: derivative is e^t cos t - e^t sin t. Hmm, not quite. Alternatively, maybe the derivative of e^t cos t + e^t sin t? Let's compute that. The derivative would be e^t cos t - e^t sin t + e^t cos t + e^t sin t = 2 e^t cos t. Not exactly, but maybe related. Wait, what if we consider integrating e^t (cos t + sin t)? Let's try integration by parts. Let me set up integration by parts for f(x).\n",
            "\n",
            "Let u = e^t, dv = (cos t + sin t) dt. Then du = e^t dt, v = ‚à´(cos t + sin t) dt. But ‚à´cos t dt = sin t + C, and ‚à´sin t dt = -cos t + C. So v = sin t - cos t + C. So applying integration by parts: ‚à´u dv = uv - ‚à´v du. So,\n",
            "\n",
            "f(x) = [e^t (sin t - cos t)] from 0 to x - ‚à´0^x (e^t)(sin t - cos t) dt.\n",
            "\n",
            "Wait, but then this seems to lead back to a similar integral. Maybe there's another way. Alternatively, perhaps we can express the integrand as the derivative of some function. Let me think. The integrand is e^t (cos t + sin t). Let's see if that is the derivative of e^t cos t or something. Wait, let's compute the derivative of e^t cos t: derivative is e^t cos t - e^t sin t = e^t (cos t - sin t). That's close but has a minus sign. Similarly, derivative of e^t sin t is e^t sin t + e^t cos t = e^t (sin t + cos t), which is the integrand! Oh, that's useful. So e^t (sin t + cos t) is the derivative of e^t sin t. Therefore, the integral of e^t (sin t + cos t) from 0 to x is [e^t sin t] from 0 to x = e^x sin x - e^0 sin 0 = e^x sin x. So f(x) = e^x sin x. That simplifies the first function. So f(x) = e^x sin x. Let me confirm by differentiating: derivative of f(x) is e^x sin x + e^x cos x = e^x (sin x + cos x), which matches the integrand. Perfect, so f(x) is indeed e^x sin x.\n",
            "\n",
            "Similarly, for g(x), which is the integral of e^t (cos t - sin t) dt. Let's see if we can find a similar expression here. The integrand is e^t cos t - e^t sin t. Let's check the derivative of e^t cos t: as before, e^t (cos t - sin t), which matches the integrand. So yes! Therefore, the integral should be e^t cos t evaluated from 0 to x, which is e^x cos x - e^0 cos 0 = e^x cos x - 1. So g(x) = e^x cos x - 1. Let me verify by differentiating: derivative of g(x) is e^x cos x - e^x sin x, which factors as e^x (cos x - sin x), the integrand. So that's correct. So g(x) = e^x cos x - 1.\n",
            "\n",
            "Alright, so now f(x) = e^x sin x and g(x) = e^x cos x - 1. Now the question is asking for the sum from n=1 to infinity of e^(2a) divided by [f^{(n)}(a)]¬≤ + [g^{(n)}(a)]¬≤. So we need to find the nth derivatives of f and g at x = a and then compute their squares and the denominator, then sum the series.\n",
            "\n",
            "First, let's find f^{(n)}(x) and g^{(n)}(x). Since f(x) = e^x sin x, let's find its derivatives. Let's compute the first few derivatives:\n",
            "\n",
            "f'(x) = e^x sin x + e^x cos x = e^x (sin x + cos x)\n",
            "f''(x) = e^x (sin x + cos x) + e^x (cos x - sin x) = e^x (2 cos x)\n",
            "f'''(x) = e^x (2 cos x) + e^x (-2 sin x) = 2 e^x (cos x - sin x)\n",
            "f''''(x) = 2 e^x (cos x - sin x) + 2 e^x (-sin x - cos x) = 2 e^x (-2 sin x) = -4 e^x sin x\n",
            "\n",
            "Hmm, Interesting. So f''''(x) = -4 e^x sin x, which is -4 f(x). So, it seems there's a pattern every 4 derivatives. Let's check g(x) as well.\n",
            "\n",
            "g(x) = e^x cos x -1. Let's find derivatives:\n",
            "\n",
            "g'(x) = e^x cos x - e^x sin x = e^x (cos x - sin x)\n",
            "g''(x) = e^x (cos x - sin x) + e^x (-sin x - cos x) = e^x ( -2 sin x )\n",
            "g'''(x) = e^x (-2 sin x) + e^x (-2 cos x) = -2 e^x (sin x + cos x)\n",
            "g''''(x) = -2 e^x (sin x + cos x) + -2 e^x (cos x - sin x) = -2 e^x (2 cos x) = -4 e^x cos x\n",
            "\n",
            "Hmm, same pattern here. Wait, so f''''(x) = -4 f(x) and g''''(x) = -4 g(x) + terms? Wait, but g''''(x) = -4 e^x cos x, and g(x) is e^x cos x -1. So actually, g''''(x) = -4 [g(x) + 1]. Let me verify that:\n",
            "\n",
            "g'''(x) is -2 e^x (sin x + cos x), which is -2 e^x (sin x + cos x), and g''''(x) is derivative of that, which is -2 e^x (sin x + cos x) + -2 e^x (cos x - sin x) = -2 e^x (2 cos x) = -4 e^x cos x. Then g''''(x) = -4 [e^x cos x] = -4 g(x) +4, since g(x) = e^x cos x -1, so -4 g(x) +4 = -4 (e^x cos x -1) +4 = -4 e^x cos x +4 +4 = -4 e^x cos x +8. Wait, that's not matching. Wait, perhaps I made a mistake here. Let me check again.\n",
            "\n",
            "Wait, g(x) = e^x cos x -1, so g''''(x) = -4 e^x cos x. Let's write g''''(x) = -4 e^x cos x = -4 [e^x \n",
            "Extracted:\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# For optional training + evaluation\n",
        "# new_dataset = dataset.train_test_split(test_size = 0.01)\n",
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        match_format_exactly,\n",
        "        match_format_approximately,\n",
        "        check_answer,\n",
        "        check_numbers,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        "\n",
        "    # For optional training + evaluation\n",
        "    # train_dataset = new_dataset[\"train\"],\n",
        "    # eval_dataset = new_dataset[\"test\"],\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlaUdxC_VHpz"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtcz_lpbVC92"
      },
      "outputs": [],
      "source": [
        "text = \"What is the sqrt of 101?\"\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 1.0,\n",
        "    top_k = 50,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    [text],\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Colxz9TAVMsi"
      },
      "source": [
        "And now with the LoRA we just trained with GRPO - we first save the LoRA first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-BcuB1VLIv"
      },
      "outputs": [],
      "source": [
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4LMOBl8boGX"
      },
      "source": [
        "Verify LoRA is actually trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SfdI-ERbpiw"
      },
      "outputs": [],
      "source": [
        "from safetensors import safe_open\n",
        "\n",
        "tensors = {}\n",
        "with safe_open(\"grpo_saved_lora/adapter_model.safetensors\", framework = \"pt\") as f:\n",
        "    # Verify both A and B are non zero\n",
        "    for key in f.keys():\n",
        "        tensor = f.get_tensor(key)\n",
        "        n_zeros = (tensor == 0).sum() / tensor.numel()\n",
        "        assert(n_zeros.item() != tensor.numel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwpbwnDBVRLg"
      },
      "source": [
        "Now we load the LoRA and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf_OY5WMVOxF"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\",   \"content\": \"What is the sqrt of 101?\"},\n",
        "]\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    tokenize = False,\n",
        ")\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 1.0,\n",
        "    top_k = 50,\n",
        "    max_tokens = 2048,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aDgFfhFYIAS"
      },
      "source": [
        "Our reasoning model is much better - it's not always correct, since we only trained it for an hour or so - it'll be better if we extend the sequence length and train for longer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NUEmHFSYNTp"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjXGTkp7YNtB"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52WMb3k_YPt8"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyEjW-WuYQIm"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V15Yhj1V9lwG"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MjX0haKBxg8k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce18fa7780ca487b922d00b92d1227a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a81a44d4a794478882f63a67987435a",
              "IPY_MODEL_dc829092cd484c2da2803e411d153389",
              "IPY_MODEL_b8b62be38e63406d8d2cb4fa6db86edc"
            ],
            "layout": "IPY_MODEL_92494cf78af649fa98dd4214d9492ea4"
          }
        },
        "5a81a44d4a794478882f63a67987435a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be1f9b2ed6264b92bbf6a475f36fe92f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_17ec6c3377464af7ac02f3548870c588",
            "value": ""
          }
        },
        "dc829092cd484c2da2803e411d153389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfdca502c8d74ef9b927b4b4c5e29f5f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9ed06dfd5364358b6c9ce5d95a3e479",
            "value": 3
          }
        },
        "b8b62be38e63406d8d2cb4fa6db86edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d9bc1eaa6b4b6b8c1a7f033a2eb2e9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_322e953615a24a72975b71c1c909cfa8",
            "value": "Loading‚Äásafetensors‚Äácheckpoint‚Äáshards:‚Äá100%‚ÄáCompleted‚Äá|‚Äá3/3‚Äá[00:03&lt;00:00,‚Äá‚Äá1.26s/it]\n"
          }
        },
        "92494cf78af649fa98dd4214d9492ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be1f9b2ed6264b92bbf6a475f36fe92f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ec6c3377464af7ac02f3548870c588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfdca502c8d74ef9b927b4b4c5e29f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ed06dfd5364358b6c9ce5d95a3e479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74d9bc1eaa6b4b6b8c1a7f033a2eb2e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "322e953615a24a72975b71c1c909cfa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2972c539a47f48d79943e29291c11d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_788efdf5542c4e6cb4e0d9d9febbb6dc",
              "IPY_MODEL_0e9b27873868462ab0ca7cbb32445552",
              "IPY_MODEL_89687394aa8b4cd597857b172cbd5652"
            ],
            "layout": "IPY_MODEL_8e08c22123044b1e93a07e522fce9b3c"
          }
        },
        "788efdf5542c4e6cb4e0d9d9febbb6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d142bbde03140a494b2598e26997c3b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_922b540434d645899d85f0e9e116071d",
            "value": ""
          }
        },
        "0e9b27873868462ab0ca7cbb32445552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f4b2c217a4b403097255990e4f06e9a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3109261387d4a68ae91abe70fb5dcdd",
            "value": 3
          }
        },
        "89687394aa8b4cd597857b172cbd5652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f40263911d1044cbb775c69b1784459e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ce5c31da70ed4f16affb06484c50a05b",
            "value": "Loading‚Äásafetensors‚Äácheckpoint‚Äáshards:‚Äá100%‚ÄáCompleted‚Äá|‚Äá3/3‚Äá[00:03&lt;00:00,‚Äá‚Äá1.28s/it]\n"
          }
        },
        "8e08c22123044b1e93a07e522fce9b3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d142bbde03140a494b2598e26997c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "922b540434d645899d85f0e9e116071d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f4b2c217a4b403097255990e4f06e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3109261387d4a68ae91abe70fb5dcdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f40263911d1044cbb775c69b1784459e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5c31da70ed4f16affb06484c50a05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc9d7f74029f40349bad2140679099fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94ebf11421ce4070a476538a1e84cf4e",
              "IPY_MODEL_b848e45976c342c08efe73d51b64dac1",
              "IPY_MODEL_fcc310e2f2af4edd8bd173b36d8e50a4"
            ],
            "layout": "IPY_MODEL_4bec0bc98cd24745a99ccbce901ddbd1"
          }
        },
        "94ebf11421ce4070a476538a1e84cf4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c7fd6694974428a151c6f6184445f9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0de1cfc3e65148fd91c7384ede502679",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=12):‚Äá100%"
          }
        },
        "b848e45976c342c08efe73d51b64dac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_707058e0ef904f8195986941ec096f53",
            "max": 731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2368d4d150f4dae90a0c849ce026a7d",
            "value": 731
          }
        },
        "fcc310e2f2af4edd8bd173b36d8e50a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b4a7c022406472588f6502e5b69c076",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7fc31e9fde424247abe0da03cb767c27",
            "value": "‚Äá731/731‚Äá[00:03&lt;00:00,‚Äá290.52‚Äáexamples/s]"
          }
        },
        "4bec0bc98cd24745a99ccbce901ddbd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c7fd6694974428a151c6f6184445f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de1cfc3e65148fd91c7384ede502679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "707058e0ef904f8195986941ec096f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2368d4d150f4dae90a0c849ce026a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b4a7c022406472588f6502e5b69c076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc31e9fde424247abe0da03cb767c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}